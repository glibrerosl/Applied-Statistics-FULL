---
title: "**Admisión en la Universidad**"
subtitle: "Estudio de Análisis Multivariado con base en un conjunto de datos de aspirantes extranjeros para ser admitidos en estudios superiores en EE.UU."
author: "Por: Giancarlo Libreros Londoño::glibrerosl@libertadores.edu.co"
date: "Estudio Multivariante Elaborado entre febrero y marzo de 2023 como actividad formativa y evaluativa del curso Análisis Multivariante de la especialización en Estadística Aplicada (modalidad virtual). *Cierre de Actualizaciones [T1: 14:33 16-feb-2023] [T2: 11:59 26-feb-2023] [T3: 11:59 5-mar-2023] [T4: 11:59 12-mar-2023]*."
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
    code_download: TRUE
    theme: lumen
bibliography: bibliografia_ME.bib
csl: apa.csl
link-citations: yes
---
<!-- Configuración Global de R -->
```{r setup, include=FALSE}
library(readxl)
library(corrplot)
library(GGally)
library(ggplot2)
library(andrews)
library(tcltk)
library(aplpack)
library(graphics)
library(corrplot)
library(MVN)
library(reshape2)
library(FactoMineR)
library(factoextra)
library(psych)
library(FactoClass)
library(cluster)
library(dendextend)
library(magrittr)

knitr::opts_chunk$set(echo=TRUE)

Admission_Dataset <- read_excel("D:/ZB/[2] Academicas/[10.1] Especializacion/[0] Cursos/[3] Ans_Multivariante/Tareas/Admission_Dataset.xlsx")
Admission_Dataset_Initial <- read_excel("D:/ZB/[2] Academicas/[10.1] Especializacion/[0] Cursos/[3] Ans_Multivariante/Tareas/Admission_Dataset_Initial.xlsx")
Nationalities <- read_excel("D:/ZB/[2] Academicas/[10.1] Especializacion/[0] Cursos/[3] Ans_Multivariante/Tareas/Nationalities.xlsx")
Admission_Dataset_Initial_Nat <- read_excel("D:/ZB/[2] Academicas/[10.1] Especializacion/[0] Cursos/[3] Ans_Multivariante/Tareas/Admission_Dataset_Initial_Nat.xlsx")
Admission_Dataset_Initial_Nat_Average <- read_excel("D:/ZB/[2] Academicas/[10.1] Especializacion/[0] Cursos/[3] Ans_Multivariante/Tareas/Admission_Dataset_Initial_Nat_Average.xlsx")
```

<a name="sec1"></a>

## **Objetivo y Anotaciones :: Fase 1**
## **[Descripciones Multivariantes]**
En términos generales, esta primera etapa de estudio mostrará cálculos, visualizaciones e interpretaciones con base en un conjunto de datos desde un enfoque de estadística descriptiva multivariante; además, de incluir una prueba estadística de normalidad multivariada sobre ellos.

El conjunto de datos de trabajo es descrito en la [sección 2](#sec2). Cabe anotar que los fundamentos teóricos provienen de notas de clase del curso **Análisis Multivariante** dictado por el profesor Juan Carlos Rubriche Cárdenas para la Especialización en Estadística Aplicada, modalidad virtual (cohorte 2022-4), de la Fundación Universitaria Los Libertadores; y de los libros: Análisis Multivariante Aplicado con R [@AMARAldas-Uriel2ed] de Joaquín Aldás y Ezequiel Uriel, Análisis Multivariante de Joseph Hair, Rolph Anderson, Ronald Tatham y William Black [@AMHair-etAl5ed], Análisis Estadístico de Datos Multivariados de Luis Guillermo Díaz Monroy y Mario Alfonso Morales Rivera [@AEDMDiaz-Morales1ed], Introducción a la Teoría Matemática de las Probabilidades y a la Estadística de Howard Tucker [@ITMPETucker1ed] y Análisis Multivariado: Estadística Multivariada Descriptiva de William David Aristizábal Rodríguez [@AMEDAristizabal2017].

Este trabajo continúa el hecho en el curso **Análisis de Regresión** dictado por el profesor Dagoberto Bermúdez para la Especialización en Estadística Aplicada, modalidad virtual (cohorte 2022-4), de la Fundación Universitaria Los Libertadores. En este la bibliografía consultada fue: probabilidad y estadística de Jay L. Devore [@PEDevore7ed], Bioestadística de Wayne W. Daniel [@BEDaniel4ed], Métodos Matemáticos de Estadística de Harald Cramer [@MMECramer1ed]; motivo por el cual se incluyen en las referencias. El trabajo hecho en Análisis de Regresión que puede ser consultado temporalmente a través de: https://rpubs.com/glibrerosl/Applied-Statistics-FULL.

Por último, este trabajo fue procesado con `r R.version.string` mediado por RStudio 2022.12.0 Build 353 en una plataforma x86_64-w64-mingw32. Además, por su naturaleza de publicación en línea y para cumplir con el requisito temporal de entrega, será actualizado, como máximo, hasta las 11:59 p.m. del lunes 13 de febrero de 2023.

<a name="sec2"></a>

## **2. Descripción de los Datos**

### 2.1. Fuente del Conjunto de Datos
El conjunto de datos de trabajo se obtuvo casi totalmente de **Kaggle**: https://www.kaggle.com/akshaydattatraykhare. Es conveniente anotar que **Kaggle** es una compañía subsidiaria de Google LLC que mantiene una comunidad online de científicos de datos y profesionales del aprendizaje automático. Esta empresa permite a sus usuarios encontrar y publicar conjuntos de datos, explorar y crear modelos en un entorno de ciencia de datos basado en la web, trabajar con otros científicos de datos e ingenieros de aprendizaje automático y participar en concursos para resolver desafíos de ciencia de datos.

### 2.2. Contexto del Conjunto de Datos
El conjunto de datos incluye métricas académicas obtenidas por estudiantes extranjeros para aspirar a acceder a universidades de EE.UU. Este conjunto de datos se actualizó por última vez en julio de 2022.

### 2.3. Descripción del Conjunto de Datos {.tabset .tabset-pills}
El conjunto de datos contiene 10 campos y 400 registros. Uno de los campos es simplemente un identificador numérico secuencial de los registros; otros tres son de naturaleza politómica; y el resto son numéricos estrictamente positivos. La lista siguiente los describe en el mismo orden, de izquierdda a derecha, como aparecen en el rango de datos que los contiene y se establece para cada campo, excepto el campo **Serial**, el tipo de variable y su escala de medición con base en la nomenclatura (tipo_de_variable::escala_de_medición[ordenamiento]):

- **Serial** (identificador): registra un número secuenciado a partir de 1 para identificar de forma única cada registro consignado en el conjunto de datos.

- **Gender** (cualitativa::nominal): registra el sexo del estudiante del cual se registraron los datos: 1 corresponde con un estudiante de sexo masculino, 0 con un estudiante de sexo femenino.

- **GRE Score** (cuantitativa::razón): registra el puntaje total GRE (examen de acceso a la universidad) obtenido por el estudiante. GRE es un componente común del proceso de admisión a colegios o universidades en EE.UU. que mide el razonamiento verbal, cuantitativo, la escritura analítica y las habilidades de pensamiento crítico que se han adquirido a lo largo de un extenso período de tiempo y que no están relacionados con campo específicos de estudio. El campo solo registra dos de los tres componentes de la evaluación: razonamiento verbal y cuantitativo, en una escala desde 260 hasta 340 puntos. El resultado ausente del puntaje corresponde con el componente de escritura analítica: calificado entre 0 y 6 puntos.

- **TOEFL Score** (cuantitativa::razón): registra el puntaje total TOEFL (prueba de inglés como idioma extranjero) obtenido por el estudiante. TOEFL es un componente común del proceso de admisión a colegios o universidades en EE.UU. por parte de estudiantes extranjeros que mide las competencias en comprensión escrita, comprensión oral, expresión oral y expresión escrita, en una escala desde 0 hasta 120 puntos.

- **SOP** (cuantitativa::razón): registra el puntaje total SOP (ensayo de declaración de propósitos o de admisión) obtenido por el estudiante. SOP es un componente común del proceso de admisión a colegios o universidades en EE.UU. que consiste en un ensayo de solicitud de ingreso escrito por el estudiante en el cual debe hacer una descripción general de quién es, en quién quiere convertirse y hasta qué punto está preparado para seguir un determinado curso en la institución educativa a la cual aspira ingresar. Este ensayo se califica con un puntaje entre 0 y 5.

- **LOR** (cuantitativa::razón): registra el puntaje total LOR (carta de recomendación) obtenido por el estudiante. LOR es un componente común del proceso de admisión a colegios o universidades en EE.UU. que consiste en una recomendación escrita, generalmente por un profesor, en la cual el redactor evalúa las cualidades, características y capacidades del estudiante recomendado en relación con su aptitud para seguir un curso en la institución educativa a la cual el estudiante aspira a ingresar. Esta carta se califica con un puntaje entre 0 y 5.

- **CGPA** (cuantitativa::razón): registra el puntaje total CGPA (promedio de calificaciones acumulativo) obtenido por el estudiante. CGPA es un componente común del proceso de admisión a colegios o universidades en EE.UU. que mide el desempeño promedio del estudiante en su escolaridad previa a la solicitud de ingreso a la institución educativa siguiente de su preferencia. Este puntaje se mide entre 0 y 4; sin embargo, en el conjunto de datos fue convertido en una escala entre 0 y 10.

- **Research** (cualitativa::nominal): registra la experiencia en investigación que posee el estudiante: 1 corresponde con que el estudiante argumenta experiencia investigativa, 0 corresponde con que no-argumenta experiencia investigativa.

- **University Rating** (cualitativa::nominal(ordenada)): registra valoración de la universidad a la cual aspira a ingresar el estudiante. Esta valoración se hace en una escala entre 1 y 5 estrellas, cinco estrellas indica la mejor valoración.

- **Chance of Admit** (cuantitativa::razón): registra la probabilidad de que el estudiante sea admitido en la universidad de su preferencia con base en los datos registrados a su nombre, salvo su sexo. Esta probrabilidad se mide entre 0 y 1.

Por último, es necesario aclarar que en el conjunto de datos los registros de las variables cualitativas fueron reescritos, según los casos, por números enteros positivos, incluido el cero. Así, los sexos en la variable **Gender** fueron reescritos como **0**:**female** y **1**:**male**; en **Research** el evidenciar o no-evidenciar investigaciones fue reescrito como **0**:**no-research** y **1**:**research**; y en **University Rating** la valoración de la universidad fue reescrita como **1**:**one_star**, **2**:**two_stars**, **3**:**three_stars**, **4**:**four_stars** y **5**:**five_stars**.

#### Estructura del Conjunto de Datos Inicial
```{r Estructura_Conjunto_de_Datos_Inicial, fig.align = 'center'}
str(Admission_Dataset_Initial)
```

#### Conjunto de Datos Inicial
```{r Conjunto_de_Datos_Inicial, fig.align = 'center'}
Admission_Dataset_Initial
```

#### Estructura del Conjunto de Datos Reescrito
```{r Estructura_Conjunto_de_Datos_Reescrito, fig.align = 'center'}
str(Admission_Dataset)
```

#### Conjunto de Datos Reescrito
```{r Conjunto_de_Datos_Reescrito, fig.align = 'center'}
Admission_Dataset
```

## **3. Estimaciones Multivariadas**
Como se menciona en [@AMEDAristizabal2017] la de media, varianza y covarianza conforman un conjunto de medidas fundamentales para describir describir el comportamiento	posicional, dispersivo y correlacional de	variables	aleatorias. En este sentido, el conjunto de datos de trabajo que posee cinco variables aleatorias numéricas, y que está representado matricialmente, estima las medidas anteriores a partir de vectores y matrices en el estudio descriptivo multivariable.

El vector de medias indica el comportamiento posicional en el sentido de valor esperado o punto medio para cada variable en relación con todos sus registros. La matriz de varianzas-covarianzas estima las dispersiones, en su diagonal principal, de cada variable del conjunto de datos respecto de cada media obtenida del vector de medias. Además, por encima o por debajo de la diagonal principal, se estiman las covarianzas entre las combinaciones de los posibles pares de variables del conjunto de datos. Para más detalles se puede consultar a [@AMEDAristizabal2017].

Lo anterior, para el conjunto de datos de trabajo, se desarrolla en la [sección 3.2.](#sec3_2)

### 3.1. Planteamiento del Problema
Con base en el conjunto de datos descrito en la [sección 2](#sec2) se calcularán e intepretarán, para las variables numéricas, el vector de medias, la matriz de varianzas-covarianzas y la matriz de correlaciones. Se recuerda que las variables numéricas (en escalada de medición de razón) son: **GRE Score**, **TOEFL Score**, **SOP**, **LOR**, **CGPA** y **Chance of Admit**.

<a name="sec3_2"></a>

### 3.2. Desarrollo del Análisis {.tabset .tabset-pills}

La navegación a través de las pestañas muestra el cálculo de los siguientes objetos: **Vector de Medias** $\bar x$, **Matriz de Varianzas-Covarianzas** $S$ y **Matriz de Correlaciones** $R$.

Con base en la pestaña **Vector de Medias y Boxplots** se puede describir que en general los datos registrados para cada una de las variables tienden a tener colas izquierdas en su distribuciones, así, las medias estimadas tienden a ser altas. Adicionalmente, en relación con la mediana, solo la variable **SOP** muestra un sesgo notorio en comparación con las demás. Además, todos los casos atípicos son de extremo inferior. Si se revisan los rangos de las variables estudiadas se puede constatar que las medias son altas compradas con los extremos superiores de cada rango.

Con base en la pestaña **Matriz de Varianzas-Covarianzas** se interpreta que, en general, y como se espera que pase, las relaciones entre las variables, estudiadas por pares, tienden a ser de proporcionalidad directa. Para el caso, se pueden observar la gráfica multivariada mostrada en la pestaña **Diagrama Conjunto de Dispersión, Distribución y Correlaciones [SA]** de la [sección 4.2.](#sec4_2)

Con base en la pestaña **Matriz de Correlaciones** y al considerar la **Matriz de Varianzas-Covarianzas** es verificable que la intensidad de las corelaciones es más alta y siempre positiva entre las variables: **TOEFL_Score**, **GRE_Score**, **CGPA** y **Chance_of_Admit**, que es esperado en relación con el fenómeno estudiado, esto se puede revisar con más detalles en la [sección 4.2.](#sec4_2)

#### Vector de Medias y Boxplots
```{r Vector_de_Medias_y_Boxplots, fig.align = 'center'}
apply(Admission_Dataset[,-c(1,2,8,9)], 2, mean)
Admission_Dataset_Reducido = Admission_Dataset[,-c(1,2,8,9)]
par(mfrow = c(1, ncol(Admission_Dataset_Reducido)))
invisible(lapply(1:ncol(Admission_Dataset_Reducido), function(i) boxplot(Admission_Dataset_Reducido[, i])))
```

#### Matriz de Varianzas-Covarianzas
```{r matriz_de_Varianzas_Covarianzas, fig.align = 'center'}
round(cov(Admission_Dataset[,-c(1,2,8,9)]),2)
```

#### Matriz de Correlaciones
```{r matriz_de_Correlaciones, fig.align = 'center'}
round(cor(Admission_Dataset[,-c(1,2,8,9)]),2)
```

## **4. Gráficas Multivariadas**
En la guía de clase de [@AMEDAristizabal2017] se menciona que, en general, los gráficos multivariados cumplen dos objetivos esenciales: primero, ayudan a comparar	el	comportamiento	de	poblaciones de estudio con base en variables categóricas y suavizan la comprensión de la estructura de correlación entre	varias variables. En este sentido, el conjunto de datos de trabajo tendrá apoyo descritivo gráfico a través de tres diagramas: uno conjunto que integra dispersión, distribución y correlaciones; otro basado en la renderización de polígonos, y por último, uno que recurre a las caras de Chernoff.

### 4.1. Planteamiento del Problema
Con base en el conjunto de datos descrito en la [sección 2](#sec2) se calcularán e intepretarán, para las variables numéricas, las gráficas multivariadas de diagrama de correlaciones, matriz de diagrama de dispersión, diagrama de estrellas y caras de Chernoff. Se recuerda que las variables numéricas (en escalada de medición de razón) son: **GRE Score**, **TOEFL Score**, **SOP**, **LOR**, **CGPA** y **Chance of Admit**.

<a name="sec4_2"></a>

### 4.2. Desarrollo del Análisis {.tabset .tabset-pills}
La navegación a través de las pestañas muestra las gráficas multivariadas de: **Diagrama Conjunto de Dispersión, Distribución y Correlaciones** (sin agrupación SA y con agrupación CA (con base en las tres variables categóricas: Gender:GE, Research:RE, University_Rating:UR)), **Diagrama de Estrellas** y **Caras de Chernoff**.

Con base en la pestaña **Diagrama Conjunto de Dispersión, Distribución y Correlaciones [SA]** se puede describir que las correlaciones más altas, mayores que $0.8$, se dan entre variables esperadas como: **TOEFL_Score**, **GRE_Score**, **CGPA** y **Chance_of_Admit**. Estas variables, según las definiciones dadas en la [sección 2](#sec2) de descripción de datos, son nucleares en el fenómeno estudiado, porque están involucradas con el historial de rendimiento académico del estudiante, su desempeño en la prueba de ingreso a la universidad, su nivel de dominio certificado del idioma inglés y sus índice de probabilidad de ingreso a la universidad a la cual aspira. Sin embargo, ninguna de ellas es descollantemente explicativa. Para más detalles puede consultarse el trabajo de análisis de regrresión formulado sobre el mismo conjunto de datos a través de: https://rpubs.com/glibrerosl/Applied-Statistics-FULL.

Complementariamente, con base en las pestañas **Diagrama Conjunto de Dispersión, Distribución y Correlaciones** en sus versiones basadas en grupos a partir de las variables categóricas: **Gender**, **Research** y **University_Rating**, se puede apreciar que comparativamente la diferenciación basada en **Gender** no muestra relevancia para elevar la probabilidad de acceso a la universidad de su elección, contrario a lo que sucede con la variable agrupadora **Research** que muestra diferenciadamente lo contrario. Es decir, que un estudiante pertenezca al grupo de aquellos que evidencia trabajo en investigación al momento de presentar su solicitud de acceso, resulta para él en una característica significativamente a favor de sus pretensiones. Por otro lado, la variable clasificadora **University_Rating**, que aporta cinco grupos, muestra que las universidades de dos y cuatro estrellas en todos los casos visualizados en el diagrama son significativas a nivel de correlación, pero, como es esperado, las de mejor rating, atraen a los mejores talentos.

Con base en la pestaña **Diagrama de Estrellas** se interpreta que hay una variedad notoria de estudiantes en términos de desempeños asociados con las variables numéricas estudiadas, incluso con la que mide el examen de proficiencia en lengua extranjera, para el caso inglés: **TOEFL_Score**. Pero, también es notoria la presencia de grupos de estudiantes con desempeños aproximadamente homogéneos en todas las variables estudiadas, aunque sus escalas de desempeño varian.

Complementariamente a los diagramas de estrellas, la pestaña **Caras de Chernoff** muestra que la variedad de estudiantes es sensible de establecer. Con relativa claridad, las **Caras de Chernoff** número 1, 10, 21 y 8, 19, 22, pueden conformar un par de grupos de estudiantes que muestran desempeños significativos en las variables medidas, aunque con cambios de escala; es decir, los del segundo grupo se desempeñan mejor que los del primero considerando todas las variables estudiadas. Esto compagina con lo mostrado en el **Diagrama de Estrellas**.

Por último, es relevante mencionar que las evidencias descriptivas expuestas en este apartado estén en contra de considerar que el conjunto de datos limitado a las variables numéricas tenga una distribución normal multivariada. Esto se estudia en la [sección 5](#sec5).

#### Diagrama Conjunto de Dispersión, Distribución y Correlaciones [SA]
```{r Diagrama_Conjunto_DDC_SA, fig.align = 'center'}
ggpairs(Admission_Dataset[,-c(1,2,8,9)])
```

#### Diagrama Conjunto de Dispersión, Distribución y Correlaciones [CA:GE]
```{r Diagrama_Conjunto_DDC_CA_GE, fig.align = 'center'}
ggpairs(Admission_Dataset_Initial, columns = c(3:7,10), aes(color = Gender, alpha = 0.5), upper = list(continuous = wrap("cor", size = 2.5)))
```

#### Diagrama Conjunto de Dispersión, Distribución y Correlaciones [CA:RE]
```{r Diagrama_Conjunto_DDC_CA_RE, fig.align = 'center'}
ggpairs(Admission_Dataset_Initial, columns = c(3:7,10), aes(color = Research, alpha = 0.5), upper = list(continuous = wrap("cor", size = 2.5)))
```

#### Diagrama Conjunto de Dispersión, Distribución y Correlaciones [CA:UR]
```{r Diagrama_Conjunto_DDC_CA_UR, fig.align = 'center'}
ggpairs(Admission_Dataset_Initial, columns = c(3:7,10), aes(color = University_Rating, alpha = 0.5), upper = list(continuous = wrap("cor", size = 2.5)))
```

#### Diagrama de Estrellas
```{r diagrama_de_Estrellas, fig.align = 'center'}
set.seed(780728)
Admission_Dataset_Muestreado = Admission_Dataset[sample(1:nrow(Admission_Dataset),23),-c(1,2,8,9)]
stars(Admission_Dataset_Muestreado, len = 1, cex = 0.4, key.loc = c(10, 2), draw.segments = TRUE)
```

#### Caras de Chernoff
```{r caras_de_Chernoff, fig.align = 'center'}
set.seed(780728)
Admission_Dataset_Muestreado = Admission_Dataset[sample(1:nrow(Admission_Dataset),23),-c(1,2,8,9)]
faces(Admission_Dataset_Muestreado)
```

<a name="sec5"></a>

## **5. Normalidad Multivariada**
Como menciona [@CPEMPorras2016] para indagar o establecer el tipo de distribución multivariada de un conjunto de datos se puede recurrir a procedimientos descriptivos, como los gráficos, o a procedimientos inferenciales, como las pruebas estadísticas. En este sentido, se alcanza generalización de resultados al usar las estos últimos, si bien los primeros apoyan a las interpretaciones.

En este apartado se contempla el uso de procedimientos inferenciales para determinar si el conjunto de datos de trabajo, en relación con sus variables numéricas, se distribuye normal multivariado (DNM). Las pruebas de normalidad multivariada (PNM) a las que será sometido son: Mardia, Henze-Zirkler, Doornik-Hansen y Royston. Para estas pruebas de normalidad los test obedecen a un nivel de significancia $\alpha = 0.05$ y a las hipótesis:$$H_0: \text {Las variables tienen una DNM}$$ $$H_1: \text {Las variables NO tienen una DNM}$$ 

La prueba de Mardia se basa en extensiones de asimetría y curtosis, el cuadrado de la distancia de Mahalanobis, la cantidad de variables $p$ por tratar y la cantidad de registros $n$. Además, considera que la prueba estadística para la asimetría tiene una distribución $\chi^2$ y la prueba estadística para la curtosis se distirbuye aproximadamente normal. Los detalles sobre los parámetros de las distribuciones pueden consultarse en el trabajo de [@CPEMPorras2016].

La prueba de Henze-Zirkler se basa en la distancia funcional, dado que si el conjunto de datos presenta una distribución normal multivariada, el estadístico de la prueba se distribuye aproximadamente como una lognormal, cuyos parámetros de media $\mu$ y varianza $\sigma^2$ pueden ser consultados en [@CPEMPorras2016].

La prueba de Doornik-Hansen está basada en la asimetría y la curtosis de un conjunto de datos multivariados, que se transforma para garantizar la independencia. Es considerada más potente que la prueba de Shapiro-Wilk para casos multivariados. Su estadístico de prueba está definido como la suma de las transformaciones al cuadrado de la asimetría y la curtosis, y sigue, aproximadamente, una distribución $\chi^2$. Los detalles de la prueba pueden ser consultados en [@OTUMNDoornik_Hansen2008].

La prueba de Royston recurre a las pruebas Shapiro-Wilk o Shapiro-Francia para probar la normalidad multivariada. Así, si  la curtosis es mayor que 3, la prueba de Royston usa Shapiro-Francia para distribuciones leptocurticas. Mientras que para distribuciones platicurticas usa Shapiro-Wilk. En ella los parámetros son obtenidos por aproximaciones polinomiales, esto puede ser consultado en [@CPEMPorras2016].

### 5.1. Planteamiento del Problema
Con base en el conjunto de datos descrito en la [sección 2](#sec2) se hará una prueba estadística de normalidad multivariada, con un nivel de significancia $\alpha=0.05$, para establecer si sus datos métricos provienen de una población normal multivariada. Se recuerda que las variables numéricas del conjunto de datos (en escalada de medición de razón) son: **GRE Score**, **TOEFL Score**, **SOP**, **LOR**, **CGPA** y **Chance of Admit**.

### 5.2. Desarrollo del Análisis {.tabset .tabset-pills}
La navegación a través de las pestañas muestra que el conjunto de datos, en relación con sus variables numéricas, no se distribuye normal multivariado. En particular:

La **PNM de Mardia** establece que si ambas pruebas (para asimetría y curtosis) indican una normalidad multivariante, los datos siguen una DNM con un nivel de significancia $\alpha=0.05$; sin embargo, el caso tratado es contrario a esto. Obsérvese a través de la pestaña **PNM Mardia** que los $p-value$ para la asimetría (Skewness) y curtoris (Kurtosis) son mayores que el nivel de significancia. Por lo tanto, las evidencias no apoyan una hipótesis de normalidad multivariada para el conjunto de datos restringido a sus variables numéricas.

La **PNM de PNM Henze-Zirkler** establece que el estadístico de prueba no se distribuye aproximadamente como lognormal dado que su $p-value$ es menor que el nivel de significancia $\alpha=0.05$, obsérvese esto a través de la pestaña **PNM Henze-Zirkler**. Así, por contrarrecíproco de la implicación formulada en la descripción de la prueba en la [sección 5](#sec5), el conjunto de datos no está apoyado por las evidencias para seguir una distribución normal multivariada.

La **PNM de Doornik-Hansen** establece que su estadístico de prueba no sigue una distribución aproximadamente $\chi^2$ dado que su $p-value$ es menor que el nivel de significancia $\alpha=0.05$, obsérvese esto a través de la pestaña **PNM Doornik-Hansen**. Por lo tanto, las evidencias están lejos de apoyar que el conjunto de datos sigue una DNM.

La **PNM de Royston** establece que el conjunto de datos reducido a sus variables numéricas no sigue una DNM, dado que su $p-value$ es menor que el nivel de significancia $\alpha=0.05$. Obsérvese esto a través de la pestaña **PNM Royston**.

En general, pudo constatarse que para un nivel de significancia $\alpha=0.05$ el conjunto de datos reducido a sus variabls numéricas no sigue una distribución normal multivariada.

#### PNM Mardia
```{r PNM_Mardia, fig.align = 'center'}
mvn(Admission_Dataset[,-c(1,2,8,9)], mvnTest="mardia")
```

#### PNM Henze-Zirkler
```{r PNM_Henze_Zirkler, fig.align = 'center'}
mvn(Admission_Dataset[,-c(1,2,8,9)], mvnTest="hz")
```

#### PNM Doornik-Hansen
```{r PNM_Doornik_Hansen, fig.align = 'center'}
mvn(Admission_Dataset[,-c(1,2,8,9)], mvnTest="dh")
```

#### PNM Royston
```{r PNM_Royston, fig.align = 'center'}
mvn(Admission_Dataset[,-c(1,2,8,9)], mvnTest="royston")
```

<a name="fase2"></a>

## **Objetivo y Anotaciones :: Fase 2**
## **[Componentes Principales]**
En términos generales, esta segunda etapa de estudio mostrará cálculos, visualizaciones e interpretaciones con base en el conjunto de datos tratado en la fase [1](#sec1), pero ahora desde un enfoque de análisis de componentes principales sobre las variables cuantitativas, que incluirá: selección, calidad de representación, contribuciones e interpretación.

Recuérdese que el conjunto de datos de trabajo es descrito en la [sección 2](#sec2) y los referentes teóricos en la [sección 1](#sec1).

Por último, este trabajo fue procesado con `r R.version.string` mediado por RStudio 2022.12.0 Build 353 en una plataforma x86_64-w64-mingw32. Además, por su naturaleza de publicación en línea y para cumplir con el requisito temporal de entrega, será actualizado, como máximo, hasta las 11:59 p.m. del domingo 26 de febrero de 2023.

<a name="sec7"></a>

## **7. Selección de Componentes**
Como es mencionado en el trabajo de [@AEDMDiaz-Morales1ed] el Análisis de Componentes Principales (en adelante ACP) reestructura un conjunto de datos multivariado a través de la reducción de la cantidad de sus variables, en cuyo transfondo es innecesario asumir ninguna distribución de probabilidad de ellas. Esta reducción es lograda a través de combinaciones lineales de las variables originales, que deberán contener la mayor variabilidad posible presente en el conjunto de datos. En este sentido, el ACP logra crear nuevas variables, conocidas como componentes principales, que poseen características estadísticas de independencia (con base en el supuesto de normalidad) y no correlación.

El ACP se logra a lo largo de las siguientes fases: generación de nuevas variables, reducción dimensional del espacio de los datos, eliminación de varaibles de poco aporte e interpretación de los componentes resultantes en el contexto del problema del cual se obtuvieron los datos. Estas fases se desarrollan entre las secciones [7](#sec7), [8](#sec8), [9](#sec9) y [10](#sec10).

### 7.1. Planteamiento del Problema
Con base en las variables cuantitativas del conjunto de datos descrito en la [sección 2](#sec2) se demanda primero establecer el porcentaje de varianza explicado por cada dimensión una vez procesado el ACP; y posteriormente, con base en el autovalor medio o usando un diagrama de sedimentación, decidir cuántos componentes retener. 

### 7.2. Desarrollo del Análisis {.tabset .tabset-pills}
La navegación a través de las pestañas muestra que el conjunto de datos, en relación con sus variables numéricas, puede ser representado por un conjuto de variables más pequeño que retiene el $77.05$ $\%$ de la variabilidad del conjunto. En particular:

La **Matriz ACP** muestra seis dimensiones donde solo la primera retiene el $77.05$ $\%$, la siguiente el $10.33$ $\%$ y las demás solo porcentajes con parte entera de una cifra. En este sentido, la representatividad de la combinación lineal que define a la dimensión 1 es significativamente alta en comparación con las demás. Como esta matriz es muda en relación con las variables originales se sigue indagando la identificación de las variables que más contribuyan a la dimensión de valor propio más alto.

La **Matriz de Correlaciones** permite continuar con las descripciones de las combinaciones lineales que conforman a la dimensión de mayor interés: la dimensión 1. Así, esta matriz, como se mostró en la [sección 3.2.](#sec3_2),  ayuda a verificar que la intensidad de las corelaciones es más alta y siempre positiva entre las variables: TOEFL_Score, GRE_Score, CGPA y Chance_of_Admit, asunto esperado en relación con el fenómeno estudiado, por lo tanto, se podría esperar que estas variables participaran en la combinación lineal que define a la dimensión 1.

La pestaña de **Valores y Vectores Propios** muestra estos objetos calculados a partir de la matriz de correlaciones del conjunto de datos. En este sentido, se garantiza que la suma de los valores propios sea igual a la dimensión de dicha matriz y a la variabilidad total del conjunto, por lo cual las proporciones de retención de variabilidad son de cálculo inmediato. Además, la matriz de vectores propios define para cada componente, en relación con cada variable del conjunto de datos, los coeficientes de la combinación lineal que la conforman, por ejemplo, con un ajuste a dos cifras decimales, la componente 1 estaría representada por la combinación lineal (donde $G$ es GRE_Score, $T$ es TOEFL_Score, $S$ es SOP, $L$ es LOR, $CG$ es CGPA y $CA$ es Chance_of_Admit y además, son variables estandarizadas):$$Componente_1 = 0.41*G+0.42*T+0.39*S+0.37*L+0.44*CG+0.43*CA$$Hasta este punto, se puede observar que se dispone de un número de dimensiones igual al número de variables tratadas, con la salvedad que las variables nuevas son incorreladas entre sí, ver la pestaña **Correlaciones Comparadas**.

Por último, el **Gráfico de Cattell** y el **Gráfico de Cattell-Kaiser**, de codo y sedimentación, inducen a la elección de una componente en la reducción de dimensión que retiene la cantidad de variabilidad suficiente para tratar el problema. Sin embargo, debe resaltarse que se propone elegir con base en criterios más usados, a cambio de criterios de aceptación universal. El **Gráfico de Cattell** muestra que los cambios en la pendiente indican que la capacidad explicativa de la dimensión 1 es alta comparada con el resto. Así, el de **Cattell-Kaiser** al conjugar el instrumento gráfico anterior con el criterio de Kaiser en la misma gráfica apoya que la cantidad de dimensiones suficientes por retener es una, aclarando que esta elección retenga un porcentaje de variabilidad adecuado para estudiar el problema.

#### Matriz ACP
```{r Matriz_ACP, fig.align = 'center'}
get_eigenvalue(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F))
```

#### Matriz de Correlaciones
```{r Matriz_de_Correlaciones}
round(cor(Admission_Dataset[,-c(1,2,8,9)]),2)
```

#### Valores y Vectores Propios
```{r Valores_y_Vectores_Propios, fig.align = 'center'}
princomp(Admission_Dataset[,-c(1,2,8,9)], cor = TRUE)$sdev^2
princomp(Admission_Dataset[,-c(1,2,8,9)], cor = TRUE)$loadings[ ,1:6]
```

#### Correlaciones Comparadas
```{r Correlaciones_Comparadas, fig.align='center'}
par(mfrow=c(1,2))
corrplot::corrplot(cor(Admission_Dataset[,-c(1,2,8,9)]), method = "color", type = "upper", number.cex = 0.4)
corrplot::corrplot(cor(princomp(Admission_Dataset[,-c(1,2,8,9)], cor = TRUE)$scores), method = "color", type = "upper", number.cex = 0.4)
```

#### Gráfico de Cattell
```{r Grafico_de_Cattell, fig.align = 'center'}
fviz_eig(PCA(Admission_Dataset[,-c(1,2,8,9)], scale.unit = T, graph = F), addlabels = T, ylim=c(0,90), main = "")
```

#### Gráfico de Cattell-Kaiser
```{r Grafico_de_Cattell_Kaiser, fig.align = 'center'}
scree(Admission_Dataset[,-c(1,2,8,9)],factors = FALSE, pc = TRUE, main ="")
```

<a name="sec8"></a>

## **8. Calidad de Representación**
Al retomar el trabajo de [@AEDMDiaz-Morales1ed] se verifica que, una vez reducida la dimensionalidad del conjunto de datos y entendido que sus variables (estandarizadas) están representadas gráficamente por proyecciones de la hiperesfera de correlaciones, es necesario iniciar la interpretación de componentes a partir de dichas correlaciones, para luego la calidad de sus representaciones dada la reducción dimensional del conjunto de datos en términos de sus variables.

### 8.1. Planteamiento del Problema
Con base en el conjunto de datos descrito en la [sección 2](#sec2) se demanda determinar la calidad de representación de las variables cuantitativas respecto a la cantidad de dimensiones calculadas que retienen la mayor cantidad de variabilidad, ver la [sección 7](#sec7).

### 8.2. Desarrollo del Análisis {.tabset .tabset-pills}
La navegación a través de las pestañas muestra que la reducción de la dimensionalidad del conjunto de datos conduce analizar las calidades de representación en términos de la escala de contribuciones relativas basada en un cociente de proyecciones con propiedades aditivas y de respuesta en escala continua entre $0$ y $1$. Así, en particular:

El **Círculo de Correlaciones** expresa que se puede concebir una compenente tipo tamaño en el sentido de que la dimensión 1 muestra en él una correlación positiva con las seis variables de interés, además cercanas a la frontera del círculo unitario y significativamente próximas al eje que la representa. Por otro lado, la dimensión 2 contrapone a las variables **LOR** y **SOP** con las demás. Otro aspecto por resaltar es la correlación mostrada entre pares de variables, que en términos del fenómeno estudiado conservan su naturaleza correlacional esperada hasta este punto del análisis. Un ejemplo resaltable es el par **SOP** y **LOR** que, en cierto sentido, están influidas por la subjetividad, véase la [sección 2](#sec2).

La **Matriz de Representación**, por otro lado, muestra valores significativamente cercanos a 1 del cociente de proyecciones coseno cuadrado en relación con la dimensión 1. En este sentido, los puntos proyectados están altamente asociados con este componente. Así, la estaña que muestra la **Calidad de Representación** indica en su escala un piso alto de $0.84$ de esta manera las calidades de representación, en relación con la componente 1, están encabezadas por **CGPA** y cierran con **SOP**. Cabe aclarar que la dimensión 2 sostiene una mejor representación de **LOR** que de **SOP**, por lo tanto, la calidad de representación de la primera en relación con la dimensión 1 se ve afectada.

Por último, las **Coordenadas Individuales** ayudan, aunque de manera menos digestiva, a identificar a nivel de observaciones a los perfiles de los registros, en este caso estudiantes, en relación con las, por lo menos, dimensiones más importantes de retención de variabilidad: las componentes 1 y 2. Por ejemplo, al observar los registros 1, 9, 23, se manifiestan las semejanzas entre 1 y 23 en oposición de ambos con 9, incluso al considerar a la variable peor representada **SOP**.

#### Círculo de Correlaciones
```{r Circulo_de_Correlaciones, fig.align = 'center'}
fviz_pca_var(PCA(Admission_Dataset[,-c(1,2,8,9)], scale.unit = T, graph = F),col.var="#3B83BD", repel = T, col.circle = "#CDCDCD", ggtheme = theme_bw())
```

#### Matriz de Representación
```{r Matriz_de_Repressentacion_COS2, fig.align = 'center'}
(get_pca_var(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F)))$cos2
```

#### Calidad de Representación
```{r Calidad_de_la_Representacion, fig.align = 'center'}
fviz_pca_var(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F), col.var="cos2", gradient.cols=c("#00AFBB","#E7B800","#FC4E07"), repel = TRUE)
```

#### Coordenadas Individuales
```{r Coordenadas_Registros, fig.align = 'center'}
head((PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F))$ind$coord, n = 23L)
```

<a name="sec9"></a>

## **9. Contribuciones**
Según el trabajo de [@AEDMDiaz-Morales1ed] la interpretación de resultados está vinculada con el cálculo de coordenadas, contribuciones, cosenos cuadrados, etc, por lo tanto, la conceptualización de las variables debe ser clara para establecerla con la mayor claridad posible, es decir, los datos deben ponerse en contexto. En este sentido, la contribución de una variable a una componente allana el camino de la interpretación de resultados. Esto se hace en este apartado en el sentido de calcular lor aportes con que cada variable participa para definir a cada componente generada.

### 9.1. Planteamiento del Problema
Con base en las variables cuantitativas del conjunto de datos descrito en la [sección 2](#sec2) se demanda determinar las contribuciones que hace cada variable a la construcción de cada componente.

### 9.2. Desarrollo del Análisis {.tabset .tabset-pills}
La navegación a través de las pestañas permite reconocer en representaciones numéricas y gráficas las contribuciones de las variables del conjunto de datos a la construcción de cada componente. Así, se entiende cuánta variabilidad explica cada variable de la variabilidad total de la componente con que esté involucrada. en particular:

La **Matriz de Contribuciones** muestra en términos relativos la retención de variabilidad que tiene cada variable en la construcción de cada componente. Así, los diagramas de barras visualizados a través de las pestañas desde **Contribuciones a D1** hasta **Contribuciones a D6**, muestran con base en diagramas de barras las respectivas contribuciones que hacen las variables para explicar la varianzar en cada componente; además, cada gráfico incluye una línea que ayuda a identificar la contribución media, esto ayuda a identificar con mayor facilidad a las variables que contribuyen con mayor explicación de variabilidad de los componentes que conforman.

En **Contribuciones a D1** se visualiza que las variables por enciama de la contribución media: **CGPA**, **Chance_of_Admit**, **TOEFL_Score** y **GRE_Score** retienen aproximadamente el $71.72$ $\%$ de la variabilidad del componente 1.

En **Contribuciones a D2** se visualiza que las variables por enciama de la contribución media: **LOR** y **SOP** retienen aproximadamente el $67.87$ $\%$ de la variabilidad del componente 2.

En **Contribuciones a D3** se visualiza que las variables por enciama de la contribución media: **SOP** y **LOR** retienen aproximadamente el $81.37$ $\%$ de la variabilidad del componente 3.

En **Contribuciones a D4** se visualiza que las variables por enciama de la contribución media: **Chance_of_Admit** y **TOEFL_Score** retienen aproximadamente el $57.76$ $\%$ de la variabilidad del componente 4.

En **Contribuciones a D5** se visualiza que las variables por enciama de la contribución media: **GRE_Score** y **TOEFL_Score** retienen aproximadamente el $95.51$ $\%$ de la variabilidad del componente 5.

Por último, en **Contribuciones a D6** se visualiza que las variables por enciama de la contribución media: **CGPA** y **Chance_of_Admit** retienen aproximadamente el $96.06$ $\%$ de la variabilidad del componente 6.

Con los datos procesados hasta ahora se puede proceder con la intepretación de los componentes.

#### Matriz de Contribuciones
```{r Matriz_de_Contribuciones, fig.align = 'center'}
(get_pca_var(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F)))$contrib
```

#### Contribuciones a D1
```{r Contribuciones_DIM_1, fig.align = 'center'}
fviz_contrib(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F), choice = "var", axes = 1, top = 10)
```

#### Contribuciones a D2
```{r Contribuciones_DIM_2, fig.align = 'center'}
fviz_contrib(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F), choice = "var", axes = 2, top = 10)
```

#### Contribuciones a D3
```{r Contribuciones_DIM_3, fig.align = 'center'}
fviz_contrib(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F), choice = "var", axes = 3, top = 10)
```

#### Contribuciones a D4
```{r Contribuciones_DIM_4, fig.align = 'center'}
fviz_contrib(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F), choice = "var", axes = 4, top = 10)
```

#### Contribuciones a D5
```{r Contribuciones_DIM_5, fig.align = 'center'}
fviz_contrib(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F), choice = "var", axes = 5, top = 10)
```

#### Contribuciones a D6
```{r Contribuciones_DIM_6, fig.align = 'center'}
fviz_contrib(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F), choice = "var", axes = 6, top = 10)
```

<a name="sec10"></a>

## **10. Interpretación**
Con base en [@AEDMDiaz-Morales1ed] se sabe que a partir de las coordenadas de los registros dimensionalmente reducidos se puede ubicar en un plano de factores para efectos de análisis e interpretación. Así, las variables reducidas son las componentes principales que se grafican como ejes en un plano, y los valores que tomen son los puntajes de las componentes. Como bien se explica en el mismo trabajo, las distancias entre los puntos definidos por los puntajes de las componentes tiene un significado relevante al ayudar a establecer semejanzas de perfiles en las observaciones hechas. Sin embargo, los valores semejantes de las variables pueden darse solo en algunas de ellas, sin esperar necesariamente a que suceda en todas. Así, se espera que las distancias en el espacio dimensional original de las observaciones queden bien representadas en el espacio reducido de las componentes.

### 10.1. Planteamiento del Problema
Con base en las variables cuantitativas del conjunto de datos descrito en la [sección 2](#sec2) se demanda definir e interpretar sus componentes principales.

### 10.2. Desarrollo del Análisis {.tabset .tabset-pills}
La navegación a través de las pestañas permite visualizar objetos gráficos y matriciales que, al incluir lo hecho en las secciones anteriores, ayudan a robustecer la interpretación de las componentes calculadas. Como se mostró en la [sección 7](#sec7), la cantidad de componentes seleccionadas se redujo (según el criterio de Kaiser) a una y se estableció que la componente 1 retiene el $77.05$ $\%$ de la variabilidad de los datos. Así, en el círculo de correlaciones de la [sección 8](#sec8) se aprecia que la representación de las variables conjugadas en la componente 1 la configuran como una de tipo tamaño, lo que puede interpretarse como una especie de índice de proporcionalidad directa. Esto también se apoya con base en el hecho de que todas las variables presentan calidades de representación entre $0.62$ y $0.88$. En consecuencia, cuanto mayor sea el valor las variables mayor será el estado de favorabilidad de que el estudiante sea admitido por la univrsidad de su preferencia. Así, dada la naturaleza de las variables esta componente puede representar para un estudiante su **medida de competitividad formativa**. Al respecto:

Las pestañas **Biplot de Variables y Registros Totales** en **UR** (University Rating), **G** (Gender) y **R** (Research), muestran, con base en las agrupaciones que estas variables categóricas pueden establecer, la representación en dimensionalidad reducida en el plano de factores de registros y dimensiones con base en los puntajes por componentes. En este sentido, es posible apreciar que las agrupaciones con base en **University_Rating** y **Research** capturan diferencias acentuadas en la distribuciones de las observaciones, contrario a la agrupación con base en **Gender**.

Por último, para facilitar la verificación de la ubicación de puntajes en el plano de componentes (en particular, siempre conformado por las componentes 1 y 2 por el interés que sucitan) y, asimismo, las semejanzas de perfiles y las correlaciones entre variables, se dispuso de las pestañas **Coordenadas Individuales [Subconjunto UR]** y **Biplot de Variables y Registros [Subconjunto UR]**. Estas muestran, con base en un subconjuto de 61 registros muestrado aleatorio simple, los puntajes por componentes y el biplot de ese subconjunto, con base en la agrupación provista por la varaible categórica **University_Rating**, sin pérdida significativa de detalles. Esto, se insiste, solo tiene fines didácticos, debido a la dificultad de identificación visual que presenta el conjunto original que contiene 400 registros.

#### Biplot de Variables y Registros [Total UR]
```{r Biplot_de_Variables_y_Registros_Total_UR, fig.align = 'center'}
data_UR <- Admission_Dataset_Initial[,-c(1,2,8)]
data_All <- cbind(Admission_Dataset_Initial[,-c(1,2,8,9)], data_UR$University_Rating)
fviz_pca_biplot(PCA(data_All, ncp = 6, scale.unit = TRUE, graph = F, quali.sup = 7), axes = c(1, 2), repel = TRUE, habillage = 7)
```

#### Biplot de Variables y Registros [Total G]
```{r Biplot_de_Variables_y_Registros_Total_G, fig.align = 'center'}
data_UR <- Admission_Dataset_Initial[,-c(1,8,9)]
data_All <- cbind(Admission_Dataset_Initial[,-c(1,2,8,9)], data_UR$Gender)
fviz_pca_biplot(PCA(data_All, ncp = 6, scale.unit = TRUE, graph = F, quali.sup = 7), axes = c(1, 2), repel = TRUE, habillage = 7)
```

#### Biplot de Variables y Registros [Total R]
```{r Biplot_de_Variables_y_Registros_Total_R, fig.align = 'center'}
data_UR <- Admission_Dataset_Initial[,-c(1,2,9)]
data_All <- cbind(Admission_Dataset_Initial[,-c(1,2,8,9)], data_UR$Research)
fviz_pca_biplot(PCA(data_All, ncp = 6, scale.unit = TRUE, graph = F, quali.sup = 7), axes = c(1, 2), repel = TRUE, habillage = 7)
```

#### Coordenadas Individuales [Subconjunto UR]
```{r Coordenadas_Individuales_Subconjunto, fig.align = 'center'}
set.seed(780728)
data_61_UR <- Admission_Dataset_Initial[sample(1:nrow(Admission_Dataset_Initial),61),-c(1,2,8)]
set.seed(780728)
data_61 <- cbind(Admission_Dataset_Initial[sample(1:nrow(Admission_Dataset_Initial),61),-c(1,2,8,9)], data_61_UR$University_Rating)
head(PCA(data_61, ncp = 6, scale.unit = T, graph = F, quali.sup = 7)$ind$coord, n = 61L)
```

#### Biplot de Variables y Registros [Subconjunto UR]
```{r Biplot_de_Variables_y_Registros_Subconjunto, fig.align = 'center'}
set.seed(780728)
data_61_UR <- Admission_Dataset_Initial[sample(1:nrow(Admission_Dataset_Initial),61),-c(1,2,8)]
set.seed(780728)
data_61 <- cbind(Admission_Dataset_Initial[sample(1:nrow(Admission_Dataset_Initial),61),-c(1,2,8,9)], data_61_UR$University_Rating)
fviz_pca_biplot(PCA(data_61, ncp = 6, scale.unit = T, graph = F, quali.sup = 7), axes = c(1, 2), repel = T, habillage = 7)
```

<a name="fase3"></a>

## **Objetivo y Anotaciones :: Fase 3**
## **[Correspondencias]**
En términos generales, esta tercera etapa de estudio mostrará cálculos, visualizaciones e interpretaciones con base en el conjunto de datos tratado en la fase [1](#sec1) y [2](#fase2), pero ahora desde un enfoque de análisis de correspondencias simples y múltiples sobre las variables cuanlitativas, que incluirá: construcción de tablas de contingencias y disyuntivas completas, calidades de representación, contribuciones e interpretaciones.

Recuérdese que el conjunto de datos de trabajo es descrito en la [sección 2](#sec2) y los referentes teóricos en la [sección 1](#sec1).

Por último, este trabajo fue procesado con `r R.version.string` mediado por RStudio 2022.12.0 Build 353 en una plataforma x86_64-w64-mingw32. Además, por su naturaleza de publicación en línea y para cumplir con el requisito temporal de entrega, será actualizado, como máximo, hasta las 11:59 p.m. del domingo 5 de marzo de 2023.

<a name="sec11"></a>

## **11. Correspondencias Simples**
Con base en el trabajo de [@AMARAldas-Uriel2ed] se sabe que el análisis de correspondencias simple (ACS) busca representar en un espacio multidimensional reducido la relación que exista entre las categorías de un par de variables categóricas. En este sentido, el ACS muestra las distancia entre los niveles de dos variables categóricas y, en consecuencia, ayuda a visualizar tablas de contingencia. Además, se establece que el número máximo de dimensiones que expliquen la asociación entre variables fila y columna es igual a uno menos el menor número de categorías de alguna de las variables involucradas. En consecuencia, el análisis de correspondencias permite describir la proximidad existente entre los perfiles de los objetos observados. Además, el ACS, que basa sus cálculos en tablas de contingencia, puede extenderse a más de dos variables categóricas, conociéndose como anáslisis de correspondencias múltiples (ACM), con base en una objeto llamado tabla disyuntiva completa.

Esta sección trata el análisis de correspondecias simple con base en pares de variables categóricas del conjunto de datos descrito en la [sección 2](#sec2). Complementariamente, la [sección 12](#sec12) muestra el análisis de correspondencias múltiples con base en las varaibles categóricas del mismo conjunto de datos.

### 11.1. Planteamiento del Problema
Con base en las variables cualitativas del conjunto de datos descrito en la [sección 2](#sec2) se demanda desarrollar el análisis de correspondencias, en principio simple, apoyado en tablas de contingencia y de frecuencias relativas y gráficos de perfiles y de puntos superpuestos en el primer plano factorial. 

### 11.2. Desarrollo del Análisis {.tabset .tabset-pills}
La navegación a través de las pestañas permite visualizar objetos matriciales y gráficos que ayudan a robustecer la interpretación del análisis de correspondencias simple (binario) entre cada par de varaibles categóricas del conjunto de datos: **Gender**, **Research** y **University_Rating**. Por ser baja la cantidad de variables categóricas se trabaja el ACS sobre las tres combinaciones posibles.

La pestaña **AC Parejas Totales** agrupa los cálculos para todas las combinaciones de parejas de variables. En particular, en **Contingencias** se hacen las siguientes lecturas de ejemplo de las tablas de contingencias: en la tabla de contingencias **Gender** vs. **Research** se encontró que 80 estudiantes de un total de 151 de sexo femenino adjuntaron evidencias de participación en actividades de investigación; además, de los 181 estudiantes que no argumentaron investigación, de un total de 400 postulados, 71 son de sexo femenino y 110 de sexo masculino. En la tabla de contingencias **Gender** vs. **University_Rating** se calculó que 14 estudiantes de un total de 249 de sexo masculino presentaron aspiraciones de ingreso a unna universidad de una estrella; además, de los 60 estudiantes que presentaron solicitudes de ingreso a universidades de cinco estrellas, 23 eran de sexo femenino y 37 de sexo masculino. Por último, en la tabla de contingencia **Research** vs. **University_Rating** se puede determinar que 59 estudiantes, de un total de 219, que presentaron evidencias de haber participado en procesos de investigación, presentaron sus aspiraciones de ingreso en universidades de cuatro estrellas; además, 75 estudiantes, de un total de 107, que se postularon en universidades de dos estrellas, lo hicieron sin evidenciar participación en procesos de investigación.

Al tomar como base las tablas de contingencia descritas antes, se presenta a través de la subpestaña **Probabilidades** las proporciones relativas en términos de los pares de variables examininados. En este sentido, a nivel de ejemplo se presentan algunas lecturas de ellas: en la tabla de probabilidades **Gender** vs. **Research** el $20.00$ $\%$ del total de estudiantes son de sexo femenino que presentaron evidencias en su aplicación de haber participado en procesos de investigación; además, el $45.25$ $\%$ del total de estudiantes no argumentó en su postulación haber participado en procesos de investigación, donde el $17.75$ $\%$ eran hombres y el $27.50$ $\%$ mujeres. En la tabla de probabilidades **Gender** vs. **University_Rating** que el $3.50$ $\%$ del total de estudiantes fueron hombres que presentaron sus postulaciones a universidades de una estrella; además, del $15.00$ $\%$ de postulados a universidades de cinco estrellas, aditivamente el $9.25$ $\%$ eran hombres y el $5.75$ $\%$ mujeres. Por último, en la tabla de probabilidades **Research** vs. **University_Rating** el $14.75$ $\%$ del total de estudiantes presentaron evidencias de participación en procesos investigativos y se postularon a universidades de cuatro estrellas; además, el $18.75$ $\%$ del total de estudiantes se postularon para ingresar a universidades de dos estrellas sin presentar evidencias de haber participado en procesos de investigación.

Como ocurre con las tablas de probabilidades o proporciones, en la subpestaña **Frecuencias [CPF y CPC]**, las frecuencias condicionadas por filas y condicionadas por columnas (respectivamente) se calcularon con base en las tablas de contingencia respectivas. Así, se pueden presentar las siguientes lecturas de ejemplo: según la matriz de frecuencias CPF de **Gender** vs. **Research** de los estudiantes de sexo femenino el $52.98$ $\%$ se postuló presentando evidencias de haber participado en procesos de investigación, por otro lado, entre los estudiantes de sexo masculino lo hizo el $55.82$ $\%$; además, según la misma matriz pero condicionada por columnas, el $39.23$ $\%$ de los estudiantes que no presentaron evidencias de haber participado en procesos de investigación fueron de sexo femenino, mientras que el $60.77$ $\%$ eran de sexo masculino. Ahora, según la matriz de frecuencias CPF de **Gender** vs. **University_Rating** el $5.62$ $\%$ de los estudiantes de sexo masculino se postuló a universidades de una estrella, mientras que el $7.95$ $\%$ de las mujeres hizo lo mismo; además, según la misma matriz pero condicionada por columnas, del total de estudiantes que se presentaron a universidades de una estrella el $46.15$ $\%$ fueron mujeres y el $53.85$ $\%$ hombres. Por último, según la matriz de frecuencias CPF de **Research** vs. **University_Rating** solo el $4.42$ $\%$ de los estudiantes que no evidenciaron participaciones en procesos de investigación se postularon para universidades de cinco estrellas, mientras que a ellas se presentaron el $23.74$ $\%$ de estudiantes que sí tenían evidencias de participación en dichos procesos. Complementariamente, según la misma matriz pero condicionada por columnas, el $13.33$ $\%$ del total de estudiantes que se presentaron a universidades de cinco estrellas estos no argumentaron haber participado en procesos de investigación, mientras que el $86.67$ $\%$ sí lo hizo.

Con base en las matrices de frecuencias se entienden los perfiles condicionados por filas y columnas que se exhiben en la subpestaña **Perfiles [CPF y CPC]**. Los gráficos de perfiles se muestran en el mismo orden de los objetos anteriormente descritos. Sin embargo, en los gráficos de perfiles se pueden cotejar las proporciones contra un individuo promedio o un perfil promedio, etiquetado con **marg**. En este sentido, los perfiles fila y columna que corresponden con las variables **Gender** y **Research** muestran distribuciones marginales cercanas entre sí; es decir, si son calculadas las proporciones totales serán aproximadamente iguales, por ejemplo: (perfiles fila) las proporciones de estudiantes de sexo masculino y femenino que se postularon sin credenciales investigativas fueron, respectivamente, $44.18$ $\%$ y $47.02$ $\%$; también, (perfiles columna) la proporción de estudiantes de sexo femenino que se postularon con o sin credenciales fueron, respectivamente, $36.53$ $\%$ y $39.23$ $\%$. Asimismo, los perfiles fila y columna que corresponden con las variables **Gender** y **University_Rating** muestran distribuciones marginales cercanas entre sí, por ejemplo: (perfiles fila) las proporciones de estudiantes de sexo masculino y femenino que se postularon a universidades de tres estrellas fueron, respectivamente, $32.13$ $\%$ y $35.10$ $\%$; también, (perfiles columna) la proporción de estudiantes de sexo femenino que se presentaron a universidades de cinco, tres y dos estrellas fueron, respectivamente, $38.33$ $\%$, $39.85$ $\%$ y $38.32$ $\%$. Por último, los perfiles fila y columna que corresponden con las variables **Research** y **University_Rating** muestran distribuciones marginales lejanas entre sí, por ejemplo: (perfiles fila) las proporciones de estudiantes que se presentaron sin o con credenciales de investigación a universidades de cinco estrellas fueron: $4.42$ $\%$ y $23.74$ $\%$; también, (perfiles columna) la proporción de estudiantes que presentaron credenciales de investigación para postularse en universidades de cinco, tres y dos estrellas fueron, respectivamente, $86.67$ $\%$, $53.38$ $\%$ y $29.91$ $\%$.

con base en las descripciones hechas es posible anticipar que los pares de variables categóricas **Gender** vs. **Research** y **Gender** vs. **University_Rating** sean independientes. Este juicio se apoya en los resultados de las pruebas de hipótesis visualizadas a través de la sub-pestaña homónima.Para estas pruebas, a un nivel de significancia $\alpha = 0.05$, las hipótesis formuladas fueron:$$H_0: \text {Las variables categóricas son independientes}$$ $$H_1: \text {las variables categóricas son dependientes}$$Asimismo, el par de variables que tuvo las pruebas a favor de la dependencia fueron **Research** y **University_Rating**, en esta prueba el $p-valor$ resultó menor o igual que el nivel de significancia y, comparativamente, el valor del estadístico $\chi^2$ fue grande. Por lo tanto, el par de variables que continuaron en análisis fueron estas últimas.

A través de la pestaña **AC Pareja Única** se despliegan las sub-pestañas relacionadas con la continuación del análisis de correspondencias entre ellas. En **Contingencias y Residuales [R-UR]** (R: Research y UR: University_Rating) se pueden visualizar las tablas de contingencias, valores esperados y residuales de la pareja de variables en curso. Respecto de las dos primeras es visualizable que el recuento observado y el recuento esperado bajo la hipótesis nula respecto de cada variable son lejanos entre sí, en este sentido, la dependencia entre las variables se robustece.  "rango_observado" son los recuentos asociados con cada categoría de datos y "rango_esperado" son los recuentos esperados para cada categoría bajo la hipótesis nula. Además, el análisis de residuales de Pearson y estandarizados muestran que las mayores desviaciones respecto a los valores esperados ocurren entre las universidades de cinco, cuatro, dos y una estrella. Asimismo, en la sub-pestaña **Contribuciones [R-UR]** puede apreciarse, comentado lo anterior, que el valor tres estrellas de la variable **University_Rating** contribuye poco en la explicación de la variabilidad del conjunto en comparación con los demás.

Por último, el resultado definitivo del análisis de correspondencias simple se muestra a través de la sub-pestaña **Correspondencia Simple Unidimensional [R-UR]**. En este apartado se establece que solo una dimensión absorbe toda la variabilidad de la pareja, por lo que la representación bidimensional en el palno de factores es irrealizable. Sin embargo,  es posible hacer una interpretación unidimensional de los resultados. Al ser requeridas las variables de soporte del AC, primero por columnas y luego por filas, las coordenadas proyectadas de la variable **University_Rating** en relación con las categorías de cinco y cuatro estrellas se presentan del lado positivo del eje dimensional creando oposiciones binarias con, respectivamente, cinco estrellas con una estrella y cuatro estrellas con dos estrellas, mientras que las universidades de tres estrellas se enccuentra técnicamente en el centro del eje. Así mismo, los tipos de universidades cinco, cuatro, dos y de una estrella, son las que más contribuyen en la configuración de la dimensión, de nuevo quedan rezagadas las universidades de tres estrellas. Además, es determinante que la calidad de representación alcanza el máximo con cada una de las variables. Un comportamiento semejante a lo expuesto puede apreciarse con la variable fila **Research**, su calidad de representación es máxima, las coordenadas de sus categorías se yuxtaponen en el eje unidimensional y sus contribuciones son aproximadamente equilibradas. De lo mencionado se interpreta que presentan asociación relevante, postiva o negativa, entre filas y columnas, las categorías (de las respectivas variables) cinco y cuatro estrellas con research, y una y dos estrellas con no-research.

Dado que la representación gráfica bidimensional fue irrealizable, se presenta en la [sección 12](#sec12) el análisis de correspondencias múltiples para lograrla.

#### AC Parejas Totales {.tabset .tabset-pills}

##### Contingencias
```{r Tablas_de_Contingencia, fig.align = 'center'}
addmargins(table(Admission_Dataset_Initial$Gender, Admission_Dataset_Initial$Research))
addmargins(table(Admission_Dataset_Initial$Gender, Admission_Dataset_Initial$University_Rating))
addmargins(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating))
```

##### Probabilidades
```{r Tablas_de_Probabilidades, fig.align = 'center'}
addmargins(prop.table(table(Admission_Dataset_Initial$Gender, Admission_Dataset_Initial$Research))*100)
addmargins(prop.table(table(Admission_Dataset_Initial$Gender, Admission_Dataset_Initial$University_Rating))*100)
addmargins(prop.table(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating))*100)
```

##### Frecuencias [CPF y CPC]
```{r Tablas_de_Frecuencias_Condicionadas, fig.align = 'center'}
round(addmargins(prop.table(table(Admission_Dataset_Initial$Gender, Admission_Dataset_Initial$Research), 1)*100, 2), 2)
round(addmargins(prop.table(table(Admission_Dataset_Initial$Gender, Admission_Dataset_Initial$Research), 2)*100, 1), 2)

round(addmargins(prop.table(table(Admission_Dataset_Initial$Gender, Admission_Dataset_Initial$University_Rating), 1)*100, 2), 2)
round(addmargins(prop.table(table(Admission_Dataset_Initial$Gender, Admission_Dataset_Initial$University_Rating), 2)*100, 1), 2)

round(addmargins(prop.table(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating), 1)*100, 2), 2)
round(addmargins(prop.table(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating), 2)*100, 1), 2)
```

##### Perfiles [CPF y CPC]
```{r Graficos_de_Perfiles, fig.align = 'center'}
plotct(table(Admission_Dataset_Initial$Gender, Admission_Dataset_Initial$Research),"row")
plotct(table(Admission_Dataset_Initial$Gender, Admission_Dataset_Initial$Research),"col")

plotct(table(Admission_Dataset_Initial$Gender, Admission_Dataset_Initial$University_Rating),"row")
plotct(table(Admission_Dataset_Initial$Gender, Admission_Dataset_Initial$University_Rating),"col")

plotct(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating),"row")
plotct(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating),"col")
```

##### Pruebas de Hipótesis
```{r Pruebas_de_Correspondencia, fig.align = 'center'}
chisq.test(table(Admission_Dataset_Initial$Gender, Admission_Dataset_Initial$Research))
chisq.test(table(Admission_Dataset_Initial$Gender, Admission_Dataset_Initial$University_Rating))
chisq.test(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating))
```

#### AC Pareja Única {.tabset .tabset-pills}

##### Contingencias y Residuales [R-UR]
```{r Contingencias_y_Residuales, fig.align = 'center'}
chisq.test(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating))$observed
chisq.test(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating))$expected 
chisq.test(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating))$residuals
chisq.test(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating))$stdres
```

##### Contribuciones [R-UR]
```{r Contribuciones_R-UR, fig.align = 'center'}
chisq.test(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating))$residuals^2/chisq.test(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating))$statistic*100
```

##### Correspondencia Simple Unidimensional [R-UR]
```{r Biplot_Correspondencia_Simple_R-UR, fig.align = 'center'}
CA(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating), graph = FALSE)$eig
CA(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating), graph = FALSE)$col
CA(table(Admission_Dataset_Initial$Research, Admission_Dataset_Initial$University_Rating), graph = FALSE)$row
```

<a name="sec12"></a>

## **12. Correspondencias Múltiples**

Recuperando de nuevo el trabajo de [@AEDMDiaz-Morales1ed] se dice que el ACS se puede extender desde tablas de contingencia hacia tablas disyuntivas completas. En estas las filas son los objetos a los cuales se les registran características de interés a través de las columnas que compilan las modalidades de las variables categóricas estudiadas de ellos. Así, el análisis de correspondencias múltiple (ACM) es el AC aplicado a una tabla disyuntiva completa. Por lo tanto, en el ACM una variable categórica asigna a cada objeto de una población una modalidad a través de la cual los particiona exclusiva y exhaustivamente.

Esta sección es desarrollada como alternativa de completitud del análisis de correspondencias simples que en la [sección 11](#sec11) fue inapreciable debido a la unidimensionalidad de la representación de los datos a nivel de proyección de las variables categóricas que cumplieron la hipótesis de dependencia. Por lo tanto, del tratamiento conjunto de todas las varaibles categóricas se espera obtener una representación en el primer plano factorial.

### 12.1. Planteamiento del Problema

Con base en las variables cualitativas del conjunto de datos descrito en la [sección 2](#sec2) se demanda desarrollar el análisis de correspondencias múltiples para lograr una representación gráfica en el primer plano factorial, debido a la imposibilidad de lograrlo en el análisis de correspondencias simple.

### 12.2. Desarrollo del Análisis {.tabset .tabset-pills}

La navegación a través de las pestañas permite visualizar objetos matriciales y gráficos que ayudan a desarrollar e interpretar el análisis de correspondencias múltiple (ACM) entre las variables categóricas del conjunto de datos descrito en la [sección 2](#sec2).

La pestaña **ACM** muestra la multidimensionalidad esperada, comparada con la unidimensionalidad del ACS de la [sección 11](#sec11), al trabajar conjuntamente con las tres variables categóricas del conjunto de datos: **Gender**, **University_Rating** y **Research**. Muestra además que las dimensiones del plano principal explican el $42.16$ $%$ del conjunto (será sobre este plano que se continuará con las interpretaciones del ACM). Además, la evidente baja concentración de absorción de varianza por parte de alguna o algunas dimensiones se reflejará en las distancias entre los perfiles de las variables categóricas.

En la pestaña **Biplot ACM** se muestran las semejanzas de perfiles entre estudiantes representados por puntos azules sobrepuestos que indican coordenadas de convergencia y las asociaciones entre algunas categorías de las variables y conjuntos de estudiantes. Cabe anotar que las semejanzas entre categoría de las variables están presentadas por sus coordenas respecto de los semiejes dimensionales, más que por sus proximidades, esto concuerda con los resultados obtenidos en la [sección 11](#sec11). Por ejemplo, en semejanza a nivel de categorías de las variables destacan los grupos: one_stars, two_stars, F y no-research por un lado, por otro, five_stars, four_stars, M y research, así como ciertos grupos evidentes de estudiantes. Complementariamente, a nivel de asociación se destaca la del grupo de estudiantes cercanos a two_stars y la de otro grupo nutrido cercano a four_stars. En general se pueden visualizar fácilmente las asociaciones entre las categorías de las variables y los grupos de estudiantes afines con ellas.

Seguidamente, la pestaña **Calidad de Representación** muestra que las categorías de la variable **Research** fueron las mejor representadas, en oposición a las categorías one_star y three_strars de la variable **University_Rating**. El resto quedó en un rango intermedio-alto de calidad de representación. Como la calidad de representación en subespacios de dimensión reducida se mide en porcentajes de inercia con respecto a la total la cercanía de un punto al origen del plano factorial indica una baja calidad de representación en él, por lo tanto, la categoría three_stars la presenta. La matriz de calidad de representación evidencia numéricamente la situación mencionada: para ella la suma de los cosenos cuadrados en las dimensiones del primer plano plano factorial solo ascienden a $0.09$, seguida de one_star que suma $0.18$.

Complementariamente, la pestaña **Contribuciones** muestra que para las dimensiones del primer plano factorial, y en concordancia con lo expresado en el párrafo anterior, las categorías de la variable **University_Rating**: one_star y three_stars, en ambas dimensiones quedan por debajop de la línea media de contribución, mientras que las categorías de la misma variable: four_stars y five_stars, aportan en ambos casos por enncima de la línea media. En este sentido, en la pestaña **Biplot con Contribuciones** se ´visualiza una representación en el primer plano factorial semejante a la obtenida en la pestaña **calidad de Representación**.

#### ACM
```{r ACM, fig.align = 'center'}
round(MCA(Admission_Dataset_Initial[1:400, -c(1,3,4,5,6,7,10)], graph = FALSE)$eig,2)
```

#### Biplot ACM
```{r Biplot_ACM, fig.align = 'center'}
fviz_mca_biplot(MCA(Admission_Dataset_Initial[1:400, -c(1,3,4,5,6,7,10)], graph = FALSE), repel = TRUE)
```

#### Calidad de Representación
```{r Calidad_de_Representacion_ACM, fig.align = 'center'}
fviz_mca_var(MCA(Admission_Dataset_Initial[1:400, -c(1,3,4,5,6,7,10)], graph = FALSE), col.var ="cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)
MCA(Admission_Dataset_Initial[1:400, -c(1,3,4,5,6,7,10)], graph = FALSE)$var$cos2
```

#### Contribuciones
```{r Contribuciones_ACM, fig.align = 'center'}
fviz_contrib(MCA(Admission_Dataset_Initial[1:400, -c(1,3,4,5,6,7,10)], graph = FALSE), choice = "var", axes = 1, top = 15)
fviz_contrib(MCA(Admission_Dataset_Initial[1:400, -c(1,3,4,5,6,7,10)], graph = FALSE), choice = "var", axes = 2, top = 15)
fviz_contrib(MCA(Admission_Dataset_Initial[1:400, -c(1,3,4,5,6,7,10)], graph = FALSE), choice = "var", axes = 3, top = 15)
fviz_contrib(MCA(Admission_Dataset_Initial[1:400, -c(1,3,4,5,6,7,10)], graph = FALSE), choice = "var", axes = 4, top = 15)
fviz_contrib(MCA(Admission_Dataset_Initial[1:400, -c(1,3,4,5,6,7,10)], graph = FALSE), choice = "var", axes = 5, top = 15)
```

#### Biplot con Contribuciones
```{r Biplot_con_Contribuciones_ACM, fig.align = 'center'}
fviz_mca_var(MCA(Admission_Dataset_Initial[1:400, -c(1,3,4,5,6,7,10)], graph = FALSE), col.var ="contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE)
```

## **Objetivo y Anotaciones :: Fase 4**
## **[Conglomerados]**
En términos generales, esta cuarta etapa de estudio mostrará cálculos, visualizaciones e interpretaciones con base en el conjunto de datos tratado en las fases [1](#sec1), [2](#fase2) y [3](#fase3), pero ahora desde un enfoque de análisis de conglomerados en versión jerárquica (dendogramas) y no-jerárquica (*K*-medias).

Recuérdese que el conjunto de datos de trabajo está descrito en la [sección 2](#sec2) y los referentes teóricos en la [sección 1](#sec1).

Por último, este trabajo fue procesado con `r R.version.string` mediado por RStudio 2022.12.0 Build 353 en una plataforma x86_64-w64-mingw32. Además, por su naturaleza de publicación en línea y para cumplir con el requisito temporal de entrega, será actualizado, como máximo, hasta las 11:59 p.m. del domingo 12 de marzo de 2023.

<a name="sec13"></a>

## **13. Agrupación Jerárquica**

### 13.1. Planteamiento del Problema

Con base en las variables cuantitativas del conjunto de datos descrito en la [sección 2](#sec2) se demanda desarrollar el análisis de conglomerados con base agrupaciones jerárquicas que se representen con dendogramas, esto implica clasificar a los objetos de trabajo con métodos aglomerativos del vecino más cercano, más lejano y de la unión mediante el promedio, soportados en la distancia euclidiana.

### 13.2. Desarrollo del Análisis {.tabset .tabset-pills}

La navegación a través de las pestañas permite visualizar objetos matriciales y gráficos que ayudan a desarrollar e interpretar el análisis de conglomerados entre las variables cuantitativas del conjunto de datos descrito en la [sección 2](#sec2).

Con el fin de visualar adecuadamente los datos, y solo con propósitos académicos, el conjunto de datos descrito en la [sección 2](#sec2) fue modificado de tres maneras. Primero, se le agregó una variable categórica clasificadora: **Nationality**. Esta variable se obtuvo del <a href = "https://www.iie.org/" title = "Institute of International Education" target = "_blank" rel = "noopener noreferrer">Institute of International Education</a> (Instituto de Educación Internacional) para una fecha equivalente a la del conjunto de datos inicial. La modificación consistió en agregar un campo que registrase para cada estudante extranjero su nacionalidad. Como las proporciones de participación de las nacionalidades de los estudiantes fueron diferentes, pero conocidas, el método de asignación fue aleatorio y ponderado con base en ellas (véase la pestaña **Campo Clasificador**). Cabe mencionar que la asignación se hizo directamente en el libro de cálculo con base en la fórmula *=INDICE([RANGO_DE_ETIQUETAS]; CONTAR.SI([RANGO_DE_PROPORCIONES_ACUMULADAS]; "<=" & ALEATORIO()) + 1)* para 400 registros. Además, el campo **Nationality** registra junto con la nacionalidad del estudiante la posición que ocupa dicho país como aportante de estudiantes extranjeros en el periodo de medición. Segundo, se estandarizaron en una escala de $0$ a $1$ todas las variables cuantitativas. Por último, se aplicó un filtro a los registros con base en la variable clasificadora y se calcularon nuevos registros promedio de las variables cuantitativas. Así, el análisis de conglomerados se hizo con base en el conjunto de datos mostrado en la pestaña **Conjunto Modificado**, en esta se muetran los primeros registros y la estructura del conjunto.

#### Campo Clasificador
```{r Campo_Clasificador, fig.align = 'center'}
as.data.frame(Nationalities)[1:24,-c(4,5,6)]
```

#### Conjunto Modificado
```{r Conjunto_Modificado, fig.align = 'center'}
head(as.data.frame(Admission_Dataset_Initial_Nat_Average))
str(as.data.frame(Admission_Dataset_Initial_Nat_Average))
```

#### Disimilaridad
```{r Disimilaridad, fig.align = 'center'}
data_ = as.data.frame(Admission_Dataset_Initial_Nat_Average)[, -c(1)]
rownames(data_) = unclass(Admission_Dataset_Initial_Nat_Average$Nationality)
fviz_dist(get_dist(data_, stand = T, method = "euclidean"), gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

#### Optimización de Mojena  {.tabset .tabset-pills}

##### Unión Simple
```{r Optimizacion_Mojena_Simple, fig.align = 'center'}
hc_single = hclust(get_dist(data_, stand = T, method = "euclidean"), method = "single")

mojena = function(hc){
  n_hd = length(hc$height)
  alp_g = 0 ; alpha = hc$height[n_hd:1]
  for(i in 1:(n_hd-1)){
    alp_g[i] = mean(alpha[(n_hd-i+1):1])+1.25*sd(alpha[(n_hd-i+1):1])
  }
  nog = sum(alp_g<= alpha[-n_hd]) + 1
  plot(alpha[-n_hd], pch=20, col=(alp_g>alpha[-n_hd])+1, main = paste("Optimal number of groups =",nog),
       ylab = expression(alpha[g]), xlab="Nodes")}

mojena(hc_single)
```

##### Unión Completa
```{r Optimizacion_Mojena_Completo, fig.align = 'center'}
hc_complete = hclust(get_dist(data_, stand = T, method = "euclidean"), method = "complete")

mojena = function(hc){
  n_hd = length(hc$height)
  alp_g = 0 ; alpha = hc$height[n_hd:1]
  for(i in 1:(n_hd-1)){
    alp_g[i] = mean(alpha[(n_hd-i+1):1])+1.25*sd(alpha[(n_hd-i+1):1])
  }
  nog = sum(alp_g<= alpha[-n_hd]) + 1
  plot(alpha[-n_hd], pch=20, col=(alp_g>alpha[-n_hd])+1, main = paste("Optimal number of groups =",nog),
       ylab = expression(alpha[g]), xlab="Nodes")}

mojena(hc_complete)
```

##### Unión Promedio
```{r Optimizacion_Mojena_Promedio, fig.align = 'center'}
hc_average = hclust(get_dist(data_, stand = T, method = "euclidean"), method = "average")

mojena = function(hc){
  n_hd = length(hc$height)
  alp_g = 0 ; alpha = hc$height[n_hd:1]
  for(i in 1:(n_hd-1)){
    alp_g[i] = mean(alpha[(n_hd-i+1):1])+1.25*sd(alpha[(n_hd-i+1):1])
  }
  nog = sum(alp_g<= alpha[-n_hd]) + 1
  plot(alpha[-n_hd], pch=20, col=(alp_g>alpha[-n_hd])+1, main = paste("Optimal number of groups =",nog),
       ylab = expression(alpha[g]), xlab="Nodes")}

mojena(hc_average)
```

#### Dendogramas Optimizados {.tabset .tabset-pills}

##### Enlace Simple
```{r Dendograma_Enlace_Simple, fig.align = 'center'}
suppressWarnings(fviz_dend(hc_single, k = 3, cex = 0.5, k_colors = "npg", color_labels_by_k = T, rect = T))
```

##### Enlace Completo
```{r Dendograma_Enlace_Completo, fig.align = 'center'}
fviz_dend(hc_complete, k = 3, cex = 0.5, k_colors = "npg", color_labels_by_k = T, rect = T)
```

##### Enlace Promedio
```{r Dendograma_Enlace_Promedio, fig.align = 'center'}
fviz_dend(hc_average, k = 4, cex = 0.5, k_colors = "npg", color_labels_by_k = T, rect = T)
```

<a name="sec14"></a>

## **14. Agrupación no-Jerárquica**

### 14.1. Planteamiento del Problema

Con base en las variables cuantitativas del conjunto de datos descrito en la [sección 2](#sec2) se demanda desarrollar el análisis de conglomerados con base agrupaciones no-jerárquicas a través del método de las *K*-medias y la representación gráfica diferenciada de las agrupaciones con base en códigos de colores.

### 14.2. Desarrollo del Análisis {.tabset .tabset-pills}

La navegación a través de las pestañas permite visualizar objetos matriciales y gráficos que ayudan a desarrollar e interpretar el análisis de conglomerados entre las variables cuantitativas del conjunto de datos descrito en la [sección 2](#sec2).

#### K-óptimos {.tabset .tabset-pills}

##### Elbow
```{r WSS, fig.align = 'center'}
fviz_nbclust(data_, kmeans, method = "wss") + geom_vline(xintercept = 3, linetype = 2)
```

##### Silhouette
```{r Silhouette, fig.align = 'center'}
fviz_nbclust(data_, kmeans, method = "silhouette")
```

##### Gap Statistic
```{r GAP_STAT, fig.align = 'center'}
fviz_nbclust(data_, kmeans, method = "gap_stat")
```

#### Resultados K-means {.tabset .tabset-pills}

##### K-óptimo [wws]
```{r K_WSS, fig.align = 'center'}
set.seed(780728)
print(kmeans(data_, 3, nstart = 25))
```

##### K-óptimo [sil]
```{r K_Silhouette, fig.align = 'center'}
set.seed(780728)
print(kmeans(data_, 2, nstart = 25))
```

#### Gráficos K-means {.tabset .tabset-pills}

##### K-óptimo [wws]
```{r G_WSS, fig.align = 'center'}
fviz_cluster(kmeans(data_, 3, nstart = 25), data = data_, palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#E7B801"), ellipse.type = "euclid", star.plot = TRUE, repel = TRUE, ggtheme = theme_minimal()
)
```

##### K-óptimo [sil]
```{r G_Silhouette, fig.align = 'center'}
fviz_cluster(kmeans(data_, 2, nstart = 25), data = data_, palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#E7B801"), ellipse.type = "euclid", star.plot = TRUE, repel = TRUE, ggtheme = theme_minimal()
)
```

## **Conclusiones**
Complementariamente a los análisis que fueron expuestos en las secciones de estudio es importante hacer una mención global sobre el problema considerado a la luz de lo obtenido.

Como se menciona en el trabajo hecho en el curso Análisis de Regresión (que puede ser consultado temporalmente a través de: https://rpubs.com/glibrerosl/Applied-Statistics-FULL), las aspiraciones de un estudiante extranjero para ingresar a una universidad norteamericana se enfrentan a un elevado grado de competición. Además, se constata, desde la perspectiva de estudio multivariable, que, por lo menos descriptivamente, una variable clasificadora categórica como el sexo, resulta muy poco significativa formar grupos diferenciados entre los estudiantes con aspiraciones de ingreso, asunto que contrasta con los relatos socio-populistas basados en falacias _ad hominem_. El dato, si es fino, siempre será objetivo.

Complementariamente, todas las pruebas de normalidad multivariante resultaron negativas, salvo que a nivel univariado la variable **CGPA** presentó distribución normal en todas ellas. Así, el deterioro de las propiedades de independencia lineal juegan a favor de la síntesis de información a través de la estimación de componentes principales. Este pudo describir una **medida de competitividad formativa** que conjuga, con una retención de $77.05$ $\%$ la variabilidad del conjunto de datos, la naturaleza interpretativa del fenómeno estudiado. Así, cuanto mayor sea el valor de las variables que registra un estudiante para aplicar a una plaza en una universidad de su elección, mayor será el estado de favorabilidad de que el estudiante sea admitido por la universidad de su preferencia.

Asimismo, el análisis de correspondencias, simple y múltiple, mostró que las universidades de mejor calificación, en particular, las de tres y cuatro estrellas tienden a captar a los estudiantes de mejor **medida de competitividad formativa**, algo esperado dada la naturaleza del fenómeno estudiado. Además, la variable categórica **Research** juega un papel determinante en la selectividad, mientras que la varaible **Gender** es indeterminante estadísticamente para aumentar las probabilidades de ingreso de un estudiante a una universidad de su preferencia.

Por último, es importante resaltar el aspecto técnico relacionado con el procesamiento estadístico hecho en este estudio a nivel de robustez, eficiencia e integración que R, RStudio y RMarkdown ofrecen al usuario para que este se pueda enfocar en él sin pasar mayores inconvenientes con el soporte documental para presentarlo.

## **Referencias**