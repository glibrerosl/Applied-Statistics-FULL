---
title: "**Admisión en la Universidad**"
subtitle: "Estudio de Análisis Multivariado con base en un conjunto de datos de aspirantes extranjeros para ser admitidos en estudios superiores en EE.UU."
author: "Por: Giancarlo Libreros Londoño::glibrerosl@libertadores.edu.co"
date: "Estudio Multivariante Elaborado entre febrero y marzo de 2023 como actividad formativa y evaluativa del curso Análisis Multivariante de la especialización en Estadística Aplicada (modalidad virtual). *Cierre de Actualizaciones [T1: 14:33 16-feb-2023] [T2: 11:59 26-feb-2023]*."
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
    code_download: TRUE
    theme: lumen
bibliography: bibliografia_ME.bib
csl: apa.csl
link-citations: yes
---
<!-- Configuración Global de R -->
```{r setup, include=FALSE}
library(readxl)
library(corrplot)
library(GGally)
library(ggplot2)
library(andrews)
library(tcltk)
library(aplpack)
library(graphics)
library(corrplot)
library(MVN)
library(reshape2)
library(FactoMineR)
library(factoextra)
library(psych)

knitr::opts_chunk$set(echo=TRUE)

Admission_Dataset <- read_excel("D:/ZB/[2] Academicas/[10.1] Especializacion/[0] Cursos/[3] Ans_Multivariante/Tareas/Admission_Dataset.xlsx")
Admission_Dataset_Initial <- read_excel("D:/ZB/[2] Academicas/[10.1] Especializacion/[0] Cursos/[3] Ans_Multivariante/Tareas/Admission_Dataset_Initial.xlsx")
```

<a name="sec1"></a>

## **Objetivo y Anotaciones [Etapa 1]**
En términos generales, esta primera etapa de estudio mostrará cálculos, visualizaciones e interpretaciones con base en un conjunto de datos desde un enfoque de estadística descriptiva multivariante; además, de incluir una prueba estadística de normalidad multivariada sobre ellos.

El conjunto de datos de trabajo es descrito en la [sección 2](#sec2). Cabe anotar que los fundamentos teóricos provienen de notas de clase del curso **Análisis Multivariante** dictado por el profesor Juan Carlos Rubriche Cárdenas para la Especialización en Estadística Aplicada, modalidad virtual (cohorte 2022-4), de la Fundación Universitaria Los Libertadores; y de los libros: Análisis Multivariante Aplicado con R [@AMARAldas-Uriel2ed] de Joaquín Aldás y Ezequiel Uriel, Análisis Multivariante de Joseph Hair, Rolph Anderson, Ronald Tatham y William Black [@AMHair-etAl5ed], Análisis Estadístico de Datos Multivariados de Luis Guillermo Díaz Monroy y Mario Alfonso Morales Rivera [@AEDMDiaz-Morales1ed], Introducción a la Teoría Matemática de las Probabilidades y a la Estadística de Howard Tucker [@ITMPETucker1ed] y Análisis Multivariado: Estadística Multivariada Descriptiva de William David Aristizábal Rodríguez [@AMEDAristizabal2017].

Este trabajo continúa el hecho en el curso **Análisis de Regresión** dictado por el profesor Dagoberto Bermúdez para la Especialización en Estadística Aplicada, modalidad virtual (cohorte 2022-4), de la Fundación Universitaria Los Libertadores. En este la bibliografía consultada fue: probabilidad y estadística de Jay L. Devore [@PEDevore7ed], Bioestadística de Wayne W. Daniel [@BEDaniel4ed], Métodos Matemáticos de Estadística de Harald Cramer [@MMECramer1ed]; motivo por el cual se incluyen en las referencias. El trabajo hecho en Análisis de Regresión que puede ser consultado temporalmente a través de: https://rpubs.com/glibrerosl/Applied-Statistics-FULL.

Por último, este trabajo fue procesado con `r R.version.string` mediado por RStudio 2022.12.0 Build 353 en una plataforma x86_64-w64-mingw32. Además, por su naturaleza de publicación en línea y para cumplir con el requisito temporal de entrega, será actualizado, como máximo, hasta las 11:59 p.m. del lunes 13 de febrero de 2023.

<a name="sec2"></a>

## **2. Descripción de los Datos**

### 2.1. Fuente del Conjunto de Datos
El conjunto de datos de trabajo se obtuvo casi totalmente de **Kaggle**: https://www.kaggle.com/akshaydattatraykhare. Es conveniente anotar que **Kaggle** es una compañía subsidiaria de Google LLC que mantiene una comunidad online de científicos de datos y profesionales del aprendizaje automático. Esta empresa permite a sus usuarios encontrar y publicar conjuntos de datos, explorar y crear modelos en un entorno de ciencia de datos basado en la web, trabajar con otros científicos de datos e ingenieros de aprendizaje automático y participar en concursos para resolver desafíos de ciencia de datos.

### 2.2. Contexto del Conjunto de Datos
El conjunto de datos incluye métricas académicas obtenidas por estudiantes extranjeros para aspirar a acceder a universidades de EE.UU. Este conjunto de datos se actualizó por última vez en julio de 2022.

### 2.3. Descripción del Conjunto de Datos {.tabset .tabset-pills}
El conjunto de datos contiene 10 campos y 400 registros. Uno de los campos es simplemente un identificador numérico secuencial de los registros; otros tres son de naturaleza politómica; y el resto son numéricos estrictamente positivos. La lista siguiente los describe en el mismo orden, de izquierdda a derecha, como aparecen en el rango de datos que los contiene y se establece para cada campo, excepto el campo **Serial**, el tipo de variable y su escala de medición con base en la nomenclatura (tipo_de_variable::escala_de_medición[ordenamiento]):

- **Serial** (identificador): registra un número secuenciado a partir de 1 para identificar de forma única cada registro consignado en el conjunto de datos.

- **Gender** (cualitativa::nominal): registra el sexo del estudiante del cual se registraron los datos: 1 corresponde con un estudiante de sexo masculino, 0 con un estudiante de sexo femenino.

- **GRE Score** (cuantitativa::razón): registra el puntaje total GRE (examen de acceso a la universidad) obtenido por el estudiante. GRE es un componente común del proceso de admisión a colegios o universidades en EE.UU. que mide el razonamiento verbal, cuantitativo, la escritura analítica y las habilidades de pensamiento crítico que se han adquirido a lo largo de un extenso período de tiempo y que no están relacionados con campo específicos de estudio. El campo solo registra dos de los tres componentes de la evaluación: razonamiento verbal y cuantitativo, en una escala desde 260 hasta 340 puntos. El resultado ausente del puntaje corresponde con el componente de escritura analítica: calificado entre 0 y 6 puntos.

- **TOEFL Score** (cuantitativa::razón): registra el puntaje total TOEFL (prueba de inglés como idioma extranjero) obtenido por el estudiante. TOEFL es un componente común del proceso de admisión a colegios o universidades en EE.UU. por parte de estudiantes extranjeros que mide las competencias en comprensión escrita, comprensión oral, expresión oral y expresión escrita, en una escala desde 0 hasta 120 puntos.

- **SOP** (cuantitativa::razón): registra el puntaje total SOP (ensayo de declaración de propósitos o de admisión) obtenido por el estudiante. SOP es un componente común del proceso de admisión a colegios o universidades en EE.UU. que consiste en un ensayo de solicitud de ingreso escrito por el estudiante en el cual debe hacer una descripción general de quién es, en quién quiere convertirse y hasta qué punto está preparado para seguir un determinado curso en la institución educativa a la cual aspira ingresar. Este ensayo se califica con un puntaje entre 0 y 5.

- **LOR** (cuantitativa::razón): registra el puntaje total LOR (carta de recomendación) obtenido por el estudiante. LOR es un componente común del proceso de admisión a colegios o universidades en EE.UU. que consiste en una recomendación escrita, generalmente por un profesor, en la cual el redactor evalúa las cualidades, características y capacidades del estudiante recomendado en relación con su aptitud para seguir un curso en la institución educativa a la cual el estudiante aspira a ingresar. Esta carta se califica con un puntaje entre 0 y 5.

- **CGPA** (cuantitativa::razón): registra el puntaje total CGPA (promedio de calificaciones acumulativo) obtenido por el estudiante. CGPA es un componente común del proceso de admisión a colegios o universidades en EE.UU. que mide el desempeño promedio del estudiante en su escolaridad previa a la solicitud de ingreso a la institución educativa siguiente de su preferencia. Este puntaje se mide entre 0 y 4; sin embargo, en el conjunto de datos fue convertido en una escala entre 0 y 10.

- **Research** (cualitativa::nominal): registra la experiencia en investigación que posee el estudiante: 1 corresponde con que el estudiante argumenta experiencia investigativa, 0 corresponde con que no-argumenta experiencia investigativa.

- **University Rating** (cualitativa::nominal(ordenada)): registra valoración de la universidad a la cual aspira a ingresar el estudiante. Esta valoración se hace en una escala entre 1 y 5 estrellas, cinco estrellas indica la mejor valoración.

- **Chance of Admit** (cuantitativa::razón): registra la probabilidad de que el estudiante sea admitido en la universidad de su preferencia con base en los datos registrados a su nombre, salvo su sexo. Esta probrabilidad se mide entre 0 y 1.

Por último, es necesario aclarar que en el conjunto de datos los registros de las variables cualitativas fueron reescritos, según los casos, por números enteros positivos, incluido el cero. Así, los sexos en la variable **Gender** fueron reescritos como **0**:**female** y **1**:**male**; en **Research** el evidenciar o no-evidenciar investigaciones fue reescrito como **0**:**no-research** y **1**:**research**; y en **University Rating** la valoración de la universidad fue reescrita como **1**:**one_star**, **2**:**two_stars**, **3**:**three_stars**, **4**:**four_stars** y **5**:**five_stars**.

#### Estructura del Conjunto de Datos Inicial
```{r Estructura_Conjunto_de_Datos_Inicial, fig.align = 'center'}
str(Admission_Dataset_Initial)
```

#### Conjunto de Datos Inicial
```{r Conjunto_de_Datos_Inicial, fig.align = 'center'}
Admission_Dataset_Initial
```

#### Estructura del Conjunto de Datos Reescrito
```{r Estructura_Conjunto_de_Datos_Reescrito, fig.align = 'center'}
str(Admission_Dataset)
```

#### Conjunto de Datos Reescrito
```{r Conjunto_de_Datos_Reescrito, fig.align = 'center'}
Admission_Dataset
```

## **3. Estimaciones Multivariadas**
Como se menciona en [@AMEDAristizabal2017] la de media, varianza y covarianza conforman un conjunto de medidas fundamentales para describir describir el comportamiento	posicional, dispersivo y correlacional de	variables	aleatorias. En este sentido, el conjunto de datos de trabajo que posee cinco variables aleatorias numéricas, y que está representado matricialmente, estima las medidas anteriores a partir de vectores y matrices en el estudio descriptivo multivariable.

El vector de medias indica el comportamiento posicional en el sentido de valor esperado o punto medio para cada variable en relación con todos sus registros. La matriz de varianzas-covarianzas estima las dispersiones, en su diagonal principal, de cada variable del conjunto de datos respecto de cada media obtenida del vector de medias. Además, por encima o por debajo de la diagonal principal, se estiman las covarianzas entre las combinaciones de los posibles pares de variables del conjunto de datos. Para más detalles se puede consultar a [@AMEDAristizabal2017].

Lo anterior, para el conjunto de datos de trabajo, se desarrolla en la [sección 3.2.](#sec3_2)

### 3.1. Planteamiento del Problema
Con base en el conjunto de datos descrito en la [sección 2](#sec2) se calcularán e intepretarán, para las variables numéricas, el vector de medias, la matriz de varianzas-covarianzas y la matriz de correlaciones. Se recuerda que las variables numéricas (en escalada de medición de razón) son: **GRE Score**, **TOEFL Score**, **SOP**, **LOR**, **CGPA** y **Chance of Admit**.

<a name="sec3_2"></a>

### 3.2. Desarrollo del Análisis {.tabset .tabset-pills}

La navegación a través de las pestañas muestra el cálculo de los siguientes objetos: **Vector de Medias** $\bar x$, **Matriz de Varianzas-Covarianzas** $S$ y **Matriz de Correlaciones** $R$.

Con base en la pestaña **Vector de Medias y Boxplots** se puede describir que en general los datos registrados para cada una de las variables tienden a tener colas izquierdas en su distribuciones, así, las medias estimadas tienden a ser altas. Adicionalmente, en relación con la mediana, solo la variable **SOP** muestra un sesgo notorio en comparación con las demás. Además, todos los casos atípicos son de extremo inferior. Si se revisan los rangos de las variables estudiadas se puede constatar que las medias son altas compradas con los extremos superiores de cada rango.

Con base en la pestaña **Matriz de Varianzas-Covarianzas** se interpreta que, en general, y como se espera que pase, las relaciones entre las variables, estudiadas por pares, tienden a ser de proporcionalidad directa. Para el caso, se pueden observar la gráfica multivariada mostrada en la pestaña **Diagrama Conjunto de Dispersión, Distribución y Correlaciones [SA]** de la [sección 4.2.](#sec4_2)

Con base en la pestaña **Matriz de Correlaciones** y al considerar la **Matriz de Varianzas-Covarianzas** es verificable que la intensidad de las corelaciones es más alta y siempre positiva entre las variables: **TOEFL_Score**, **GRE_Score**, **CGPA** y **Chance_of_Admit**, que es esperado en relación con el fenómeno estudiado, esto se puede revisar con más detalles en la [sección 4.2.](#sec4_2)

#### Vector de Medias y Boxplots
```{r Vector_de_Medias_y_Boxplots, fig.align = 'center'}
apply(Admission_Dataset[,-c(1,2,8,9)], 2, mean)
Admission_Dataset_Reducido = Admission_Dataset[,-c(1,2,8,9)]
par(mfrow = c(1, ncol(Admission_Dataset_Reducido)))
invisible(lapply(1:ncol(Admission_Dataset_Reducido), function(i) boxplot(Admission_Dataset_Reducido[, i])))
```

#### Matriz de Varianzas-Covarianzas
```{r matriz_de_Varianzas_Covarianzas, fig.align = 'center'}
round(cov(Admission_Dataset[,-c(1,2,8,9)]),2)
```

#### Matriz de Correlaciones
```{r matriz_de_Correlaciones, fig.align = 'center'}
round(cor(Admission_Dataset[,-c(1,2,8,9)]),2)
```

## **4. Gráficas Multivariadas**
En la guía de clase de [@AMEDAristizabal2017] se menciona que, en general, los gráficos multivariados cumplen dos objetivos esenciales: primero, ayudan a comparar	el	comportamiento	de	poblaciones de estudio con base en variables categóricas y suavizan la comprensión de la estructura de correlación entre	varias variables. En este sentido, el conjunto de datos de trabajo tendrá apoyo descritivo gráfico a través de tres diagramas: uno conjunto que integra dispersión, distribución y correlaciones; otro basado en la renderización de polígonos, y por último, uno que recurre a las caras de Chernoff.

### 4.1. Planteamiento del Problema
Con base en el conjunto de datos descrito en la [sección 2](#sec2) se calcularán e intepretarán, para las variables numéricas, las gráficas multivariadas de diagrama de correlaciones, matriz de diagrama de dispersión, diagrama de estrellas y caras de Chernoff. Se recuerda que las variables numéricas (en escalada de medición de razón) son: **GRE Score**, **TOEFL Score**, **SOP**, **LOR**, **CGPA** y **Chance of Admit**.

<a name="sec4_2"></a>

### 4.2. Desarrollo del Análisis {.tabset .tabset-pills}
La navegación a través de las pestañas muestra las gráficas multivariadas de: **Diagrama Conjunto de Dispersión, Distribución y Correlaciones** (sin agrupación SA y con agrupación CA (con base en las tres variables categóricas: Gender:GE, Research:RE, University_Rating:UR)), **Diagrama de Estrellas** y **Caras de Chernoff**.

Con base en la pestaña **Diagrama Conjunto de Dispersión, Distribución y Correlaciones [SA]** se puede describir que las correlaciones más altas, mayores que $0.8$, se dan entre variables esperadas como: **TOEFL_Score**, **GRE_Score**, **CGPA** y **Chance_of_Admit**. Estas variables, según las definiciones dadas en la [sección 2](#sec2) de descripción de datos, son nucleares en el fenómeno estudiado, porque están involucradas con el historial de rendimiento académico del estudiante, su desempeño en la prueba de ingreso a la universidad, su nivel de dominio certificado del idioma inglés y sus índice de probabilidad de ingreso a la universidad a la cual aspira. Sin embargo, ninguna de ellas es descollantemente explicativa. Para más detalles puede consultarse el trabajo de análisis de regrresión formulado sobre el mismo conjunto de datos a través de: https://rpubs.com/glibrerosl/Applied-Statistics-FULL.

Complementariamente, con base en las pestañas **Diagrama Conjunto de Dispersión, Distribución y Correlaciones** en sus versiones basadas en grupos a partir de las variables categóricas: **Gender**, **Research** y **University_Rating**, se puede apreciar que comparativamente la diferenciación basada en **Gender** no muestra relevancia para elevar la probabilidad de acceso a la universidad de su elección, contrario a lo que sucede con la variable agrupadora **Research** que muestra diferenciadamente lo contrario. Es decir, que un estudiante pertenezca al grupo de aquellos que evidencia trabajo en investigación al momento de presentar su solicitud de acceso, resulta para él en una característica significativamente a favor de sus pretensiones. Por otro lado, la variable clasificadora **University_Rating**, que aporta cinco grupos, muestra que las universidades de dos y cuatro estrellas en todos los casos visualizados en el diagrama son significativas a nivel de correlación, pero, como es esperado, las de mejor rating, atraen a los mejores talentos.

Con base en la pestaña **Diagrama de Estrellas** se interpreta que hay una variedad notoria de estudiantes en términos de desempeños asociados con las variables numéricas estudiadas, incluso con la que mide el examen de proficiencia en lengua extranjera, para el caso inglés: **TOEFL_Score**. Pero, también es notoria la presencia de grupos de estudiantes con desempeños aproximadamente homogéneos en todas las variables estudiadas, aunque sus escalas de desempeño varian.

Complementariamente a los diagramas de estrellas, la pestaña **Caras de Chernoff** muestra que la variedad de estudiantes es sensible de establecer. Con relativa claridad, las **Caras de Chernoff** número 1, 10, 21 y 8, 19, 22, pueden conformar un par de grupos de estudiantes que muestran desempeños significativos en las variables medidas, aunque con cambios de escala; es decir, los del segundo grupo se desempeñan mejor que los del primero considerando todas las variables estudiadas. Esto compagina con lo mostrado en el **Diagrama de Estrellas**.

Por último, es relevante mencionar que las evidencias descriptivas expuestas en este apartado estén en contra de considerar que el conjunto de datos limitado a las variables numéricas tenga una distribución normal multivariada. Esto se estudia en la [sección 5](#sec5).

#### Diagrama Conjunto de Dispersión, Distribución y Correlaciones [SA]
```{r Diagrama_Conjunto_DDC_SA, fig.align = 'center'}
ggpairs(Admission_Dataset[,-c(1,2,8,9)])
```

#### Diagrama Conjunto de Dispersión, Distribución y Correlaciones [CA:GE]
```{r Diagrama_Conjunto_DDC_CA_GE, fig.align = 'center'}
ggpairs(Admission_Dataset_Initial, columns = c(3:7,10), aes(color = Gender, alpha = 0.5), upper = list(continuous = wrap("cor", size = 2.5)))
```

#### Diagrama Conjunto de Dispersión, Distribución y Correlaciones [CA:RE]
```{r Diagrama_Conjunto_DDC_CA_RE, fig.align = 'center'}
ggpairs(Admission_Dataset_Initial, columns = c(3:7,10), aes(color = Research, alpha = 0.5), upper = list(continuous = wrap("cor", size = 2.5)))
```

#### Diagrama Conjunto de Dispersión, Distribución y Correlaciones [CA:UR]
```{r Diagrama_Conjunto_DDC_CA_UR, fig.align = 'center'}
ggpairs(Admission_Dataset_Initial, columns = c(3:7,10), aes(color = University_Rating, alpha = 0.5), upper = list(continuous = wrap("cor", size = 2.5)))
```

#### Diagrama de Estrellas
```{r diagrama_de_Estrellas, fig.align = 'center'}
set.seed(780728)
Admission_Dataset_Muestreado = Admission_Dataset[sample(1:nrow(Admission_Dataset),23),-c(1,2,8,9)]
stars(Admission_Dataset_Muestreado, len = 1, cex = 0.4, key.loc = c(10, 2), draw.segments = TRUE)
```

#### Caras de Chernoff
```{r caras_de_Chernoff, fig.align = 'center'}
set.seed(780728)
Admission_Dataset_Muestreado = Admission_Dataset[sample(1:nrow(Admission_Dataset),23),-c(1,2,8,9)]
faces(Admission_Dataset_Muestreado)
```

<a name="sec5"></a>

## **5. Normalidad Multivariada**
Como menciona [@CPEMPorras2016] para indagar o establecer el tipo de distribución multivariada de un conjunto de datos se puede recurrir a procedimientos descriptivos, como los gráficos, o a procedimientos inferenciales, como las pruebas estadísticas. En este sentido, se alcanza generalización de resultados al usar las estos últimos, si bien los primeros apoyan a las interpretaciones.

En este apartado se contempla el uso de procedimientos inferenciales para determinar si el conjunto de datos de trabajo, en relación con sus variables numéricas, se distribuye normal multivariado (DNM). Las pruebas de normalidad multivariada (PNM) a las que será sometido son: Mardia, Henze-Zirkler, Doornik-Hansen y Royston. Para estas pruebas de normalidad los test obedecen a un nivel de significancia $\alpha = 0.05$ y a las hipótesis:$$H_0: \text {Las variables tienen una DNM}$$ $$H_1: \text {Las variables NO tienen una DNM}$$ 

La prueba de Mardia se basa en extensiones de asimetría y curtosis, el cuadrado de la distancia de Mahalanobis, la cantidad de variables $p$ por tratar y la cantidad de registros $n$. Además, considera que la prueba estadística para la asimetría tiene una distribución $\chi^2$ y la prueba estadística para la curtosis se distirbuye aproximadamente normal. Los detalles sobre los parámetros de las distribuciones pueden consultarse en el trabajo de [@CPEMPorras2016].

La prueba de Henze-Zirkler se basa en la distancia funcional, dado que si el conjunto de datos presenta una distribución normal multivariada, el estadístico de la prueba se distribuye aproximadamente como una lognormal, cuyos parámetros de media $\mu$ y varianza $\sigma^2$ pueden ser consultados en [@CPEMPorras2016].

La prueba de Doornik-Hansen está basada en la asimetría y la curtosis de un conjunto de datos multivariados, que se transforma para garantizar la independencia. Es considerada más potente que la prueba de Shapiro-Wilk para casos multivariados. Su estadístico de prueba está definido como la suma de las transformaciones al cuadrado de la asimetría y la curtosis, y sigue, aproximadamente, una distribución $\chi^2$. Los detalles de la prueba pueden ser consultados en [@OTUMNDoornik_Hansen2008].

La prueba de Royston recurre a las pruebas Shapiro-Wilk o Shapiro-Francia para probar la normalidad multivariada. Así, si  la curtosis es mayor que 3, la prueba de Royston usa Shapiro-Francia para distribuciones leptocurticas. Mientras que para distribuciones platicurticas usa Shapiro-Wilk. En ella los parámetros son obtenidos por aproximaciones polinomiales, esto puede ser consultado en [@CPEMPorras2016].

### 5.1. Planteamiento del Problema
Con base en el conjunto de datos descrito en la [sección 2](#sec2) se hará una prueba estadística de normalidad multivariada, con un nivel de significancia $\alpha=0.05$, para establecer si sus datos métricos provienen de una población normal multivariada. Se recuerda que las variables numéricas del conjunto de datos (en escalada de medición de razón) son: **GRE Score**, **TOEFL Score**, **SOP**, **LOR**, **CGPA** y **Chance of Admit**.

### 5.2. Desarrollo del Análisis {.tabset .tabset-pills}
La navegación a través de las pestañas muestra que el conjunto de datos, en relación con sus variables numéricas, no se distribuye normal multivariado. En particular:

La **PNM de Mardia** establece que si ambas pruebas (para asimetría y curtosis) indican una normalidad multivariante, los datos siguen una DNM con un nivel de significancia $\alpha=0.05$; sin embargo, el caso tratado es contrario a esto. Obsérvese a través de la pestaña **PNM Mardia** que los $p-value$ para la asimetría (Skewness) y curtoris (Kurtosis) son mayores que el nivel de significancia. Por lo tanto, las evidencias no apoyan una hipótesis de normalidad multivariada para el conjunto de datos restringido a sus variables numéricas.

La **PNM de PNM Henze-Zirkler** establece que el estadístico de prueba no se distribuye aproximadamente como lognormal dado que su $p-value$ es menor que el nivel de significancia $\alpha=0.05$, obsérvese esto a través de la pestaña **PNM Henze-Zirkler**. Así, por contrarrecíproco de la implicación formulada en la descripción de la prueba en la [sección 5](#sec5), el conjunto de datos no está apoyado por las evidencias para seguir una distribución normal multivariada.

La **PNM de Doornik-Hansen** establece que su estadístico de prueba no sigue una distribución aproximadamente $\chi^2$ dado que su $p-value$ es menor que el nivel de significancia $\alpha=0.05$, obsérvese esto a través de la pestaña **PNM Doornik-Hansen**. Por lo tanto, las evidencias están lejos de apoyar que el conjunto de datos sigue una DNM.

La **PNM de Royston** establece que el conjunto de datos reducido a sus variables numéricas no sigue una DNM, dado que su $p-value$ es menor que el nivel de significancia $\alpha=0.05$. Obsérvese esto a través de la pestaña **PNM Royston**.

En general, pudo constatarse que para un nivel de significancia $\alpha=0.05$ el conjunto de datos reducido a sus variabls numéricas no sigue una distribución normal multivariada.

#### PNM Mardia
```{r PNM_Mardia, fig.align = 'center'}
mvn(Admission_Dataset[,-c(1,2,8,9)], mvnTest="mardia")
```

#### PNM Henze-Zirkler
```{r PNM_Henze_Zirkler, fig.align = 'center'}
mvn(Admission_Dataset[,-c(1,2,8,9)], mvnTest="hz")
```

#### PNM Doornik-Hansen
```{r PNM_Doornik_Hansen, fig.align = 'center'}
mvn(Admission_Dataset[,-c(1,2,8,9)], mvnTest="dh")
```

#### PNM Royston
```{r PNM_Royston, fig.align = 'center'}
mvn(Admission_Dataset[,-c(1,2,8,9)], mvnTest="royston")
```

## **Objetivo y Anotaciones [Etapa 2]**
En términos generales, esta segunda etapa de estudio mostrará cálculos, visualizaciones e interpretaciones con base el conjunto de datos tratado en la Etapa 1, pero ahora desde un enfoque de análisis de componentes principales sobre las variables cuantitativas, que incluirá: selección, calidad de representación, contribuciones e interpretación.

Recuérdese que el conjunto de datos de trabajo es descrito en la [sección 2](#sec2) y los referentes teóricos en la [sección 1](#sec1).

Por último, este trabajo fue procesado con `r R.version.string` mediado por RStudio 2022.12.0 Build 353 en una plataforma x86_64-w64-mingw32. Además, por su naturaleza de publicación en línea y para cumplir con el requisito temporal de entrega, será actualizado, como máximo, hasta las 11:59 p.m. del domingo 26 de febrero de 2023.

<a name="sec7"></a>

## **7. Selección de Componentes**
Como es mencionado en el trabajo de [@AEDMDiaz-Morales1ed] el Análisis de Componentes Principales (en adelante ACP) reestructura un conjunto de datos multivariado a través de la reducción de la cantidad de sus variables, en cuyo transfondo es innecesario asumir ninguna distribución de probabilidad de ellas. Esta reducción es lograda a través de combinaciones lineales de las variables originales, que deberán contener la mayor variabilidad posible presente en el conjunto de datos. En este sentido, el ACP logra crear nuevas variables, conocidas como componentes principales, que poseen características estadísticas de independencia (con base en el supuesto de normalidad) y no correlación.

El ACP se logra a lo largo de las siguientes fases: generación de nuevas variables, reducción dimensional del espacio de los datos, eliminación de varaibles de poco aporte e interpretación de los componentes resultantes en el contexto del problema del cual se obtuvieron los datos. Estas fases se desarrollan entre las secciones [7](#sec7), [8](#sec8), [9](#sec9) y [10](#sec10).

### 7.1. Planteamiento del Problema
Con base en el conjunto de datos descrito en la [sección 2](#sec2) se demanda primero establecer el porcentaje de varianza explicado por cada dimensión una vez procesado el ACP; y posteriormente, con base en el autovalor medio o usando un diagrama de sedimentación, decidir cuántos componentes retener. 

### 7.2. Desarrollo del Análisis {.tabset .tabset-pills}
La navegación a través de las pestañas muestra que el conjunto de datos, en relación con sus variables numéricas, puede ser representado por un conjuto de variables más pequeño que retiene el $77.05$ $\%$ de la variabilidad del conjunto. En particular:

La **Matriz ACP** muestra seis dimensiones donde solo la primera retiene el $77.05$ $\%$, la siguiente el $10.33$ $\%$ y las demás solo porcentajes con parte entera de una cifra. En este sentido, la representatividad de la combinación lineal que define a la dimensión 1 es significativamente alta en comparación con las demás. Como esta matriz es muda en relación con las variables originales se sigue indagando la identificación de las variables que más contribuyan a la dimensión de valor propio más alto.

La **Matriz de Correlaciones** permite continuar con las descripciones de las combinaciones lineales que conforman a la dimensión de mayor interés: la dimensión 1. Así, esta matriz, como se mostró en la [sección 3.2.](@sec3_2),  ayuda a verificar que la intensidad de las corelaciones es más alta y siempre positiva entre las variables: TOEFL_Score, GRE_Score, CGPA y Chance_of_Admit, asunto esperado en relación con el fenómeno estudiado, por lo tanto, se podría esperar que estas variables participaran en la combinación lineal que define a la dimensión 1.

La pestaña de **Valores y Vectores Propios** muestra estos objetos calculados a partir de la matriz de correlaciones del conjunto de datos. En este sentido, se garantiza que la suma de los valores propios sea igual a la dimensión de dicha matriz y a la variabilidad total del conjunto, por lo cual las proporciones de retención de variabilidad son de cálculo inmediato. Además, la matriz de vectores propios define para cada componente, en relación con cada variable del conjunto de datos, los coeficientes de la combinación lineal que la conforman, por ejemplo, con un ajuste a dos cifras decimales, la componente 1 estaría representada por la combinación lineal (donde $G$ es GRE_Score, $T$ es TOEFL_Score, $S$ es SOP, $L$ es LOR, $CG$ es CGPA y $CA$ es Chance_of_Admit y además, son variables estandarizadas):$$Componente_1 = 0.41*G+0.42*T+0.39*S+0.37*L+0.44*CG+0.43*CA$$Hasta este punto, se puede observar que se dispone de un número de dimensiones igual al número de variables tratadas, con la salvedad que las variables nuevas son incorreladas entre sí, ver la pestaña **Correlaciones Comparadas**.

Por último, el **Gráfico de Cattell** y el **Gráfico de Cattell-Kaiser**, de codo y sedimentación, inducen a la elección de una componente en la reducción de dimensión que retiene la cantidad de variabilidad suficiente para tratar el problema. Sin embargo, debe resaltarse que se propone elegir con base en criterios más usados, a cambio de criterios de aceptación universal. El **Gráfico de Cattell** muestra que los cambios en la pendiente indican que la capacidad explicativa de la dimensión 1 es alta comparada con el resto. Así, el de **Cattell-Kaiser** al conjugar el instrumento gráfico anterior con el criterio de Kaiser en la misma gráfica apoya que la cantidad de dimensiones suficientes por retener es una, aclarando que esta elección retenga un porcentaje de variabilidad adecuado para estudiar el problema.

#### Matriz ACP
```{r Matriz_ACP, fig.align = 'center'}
get_eigenvalue(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F))
```

#### Matriz de Correlaciones
```{r Matriz_de_Correlaciones}
round(cor(Admission_Dataset[,-c(1,2,8,9)]),2)
```

#### Valores y Vectores Propios
```{r Valores_y_Vectores_Propios, fig.align = 'center'}
princomp(Admission_Dataset[,-c(1,2,8,9)], cor = TRUE)$sdev^2
princomp(Admission_Dataset[,-c(1,2,8,9)], cor = TRUE)$loadings[ ,1:6]
```

#### Correlaciones Comparadas
```{r Correlaciones_Comparadas, fig.align='center'}
par(mfrow=c(1,2))
corrplot::corrplot(cor(Admission_Dataset[,-c(1,2,8,9)]), method = "color", type = "upper", number.cex = 0.4)
corrplot::corrplot(cor(princomp(Admission_Dataset[,-c(1,2,8,9)], cor = TRUE)$scores), method = "color", type = "upper", number.cex = 0.4)
```

#### Gráfico de Cattell
```{r Grafico_de_Cattell, fig.align = 'center'}
fviz_eig(PCA(Admission_Dataset[,-c(1,2,8,9)], scale.unit = TRUE, graph = F), addlabels = TRUE, ylim=c(0,90), main = "")
```

#### Gráfico de Cattell-Kaiser
```{r Grafico_de_Cattell_Kaiser, fig.align = 'center'}
scree(Admission_Dataset[,-c(1,2,8,9)],factors = FALSE, pc = TRUE, main ="")
```

<a name="sec8"></a>

## **8. Calidad de Representación**
Al retomar el trabajo de [@AEDMDiaz-Morales1ed]

### 8.1. Planteamiento del Problema
Con base en el conjunto de datos descrito en la [sección 2](#sec2) se demanda determinar la calidad de representación de las variables respecto a todas las dimensiones calculadas en la [sección 7](#sec7).

### 8.2. Desarrollo del Análisis {.tabset .tabset-pills}

#### Matriz de Representación COS2
```{r Matriz_de_Repressentacion_COS2, fig.align = 'center'}
(get_pca_var(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F)))$cos2
```

#### Calidad de la Representación COS2
```{r Calidad_de_la_Representacion, fig.align = 'center'}
fviz_pca_var(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F), col.var="cos2", gradient.cols=c("#00AFBB","#E7B800","#FC4E07"), repel = TRUE)
```

#### Coordenadas Individuales
```{r Coordenadas_Registros, fig.align = 'center'}
head((PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F))$ind$coord, n = 23L)
head(princomp(Admission_Dataset[,-c(1,2,8,9)], cor = TRUE)$scores, n = 37L)
```

<a name="sec9"></a>

## **9. Contribuciones**

### 9.1. Planteamiento del Problema
Con base en el conjunto de datos descrito en la [sección 2](#sec2) 

### 9.2. Desarrollo del Análisis {.tabset .tabset-pills}

#### Matriz de Contribuciones
```{r Matriz_de_Contribuciones, fig.align = 'center'}
(get_pca_var(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F)))$contrib
```

#### Contribuciones a D1
```{r Contribuciones_DIM_1, fig.align = 'center'}
fviz_contrib(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F), choice = "var", axes = 1, top = 10)
```

#### Contribuciones a D2
```{r Contribuciones_DIM_2, fig.align = 'center'}
fviz_contrib(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F), choice = "var", axes = 2, top = 10)
```

#### Contribuciones a D3
```{r Contribuciones_DIM_3, fig.align = 'center'}
fviz_contrib(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F), choice = "var", axes = 3, top = 10)
```

#### Contribuciones a D4
```{r Contribuciones_DIM_4, fig.align = 'center'}
fviz_contrib(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F), choice = "var", axes = 4, top = 10)
```

#### Contribuciones a D5
```{r Contribuciones_DIM_5, fig.align = 'center'}
fviz_contrib(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F), choice = "var", axes = 5, top = 10)
```

#### Contribuciones a D6
```{r Contribuciones_DIM_6, fig.align = 'center'}
fviz_contrib(PCA(Admission_Dataset[,-c(1,2,8,9)], ncp = 6, scale.unit = TRUE, graph = F), choice = "var", axes = 6, top = 10)
```


<a name="sec10"></a>

## **10. Interpretación de Componentes**

### 10.1. Planteamiento del Problema

### 10.2. Desarrollo del Análisis {.tabset .tabset-pills}

#### Biplot de Variables y Registros [Total]
```{r Biplot_de_Variables_y_Registros_Total, fig.align = 'center'}
data_UR <- Admission_Dataset_Initial[,-c(1,2,8)]
data_All <- cbind(Admission_Dataset_Initial[,-c(1,2,8,9)], data_UR$University_Rating)
fviz_pca_biplot(PCA(data_All, ncp = 6, scale.unit = TRUE, graph = F, quali.sup = 7), axes = c(1, 2), repel = TRUE, habillage = 7)
```

#### Biplot de Variables y Registros [Subconjunto]
```{r Biplot_de_Variables_y_Registros_Subconjunto, fig.align = 'center'}
set.seed(780728)
data_100_UR <- Admission_Dataset_Initial[sample(1:nrow(Admission_Dataset_Initial),100),-c(1,2,8)]
set.seed(780728)
data_100 <- cbind(Admission_Dataset_Initial[sample(1:nrow(Admission_Dataset_Initial),100),-c(1,2,8,9)], data_100_UR$University_Rating)
fviz_pca_biplot(PCA(data_100, ncp = 6, scale.unit = TRUE, graph = F, quali.sup = 7), axes = c(1, 2), repel = TRUE, habillage = 7)
```

## **Conclusiones**
Complementariamente a los análisis que fueron expuestos en las secciones de estudio es importante hacer una mención global sobre el problema considerado a la luz de lo obtenido.

Como se menciona en el trabajo hecho en el curso Análisis de Regresión (que puede ser consultado temporalmente a través de: https://rpubs.com/glibrerosl/Applied-Statistics-FULL), las aspiraciones de un estudiante extranjero para ingresar a una universidad norteamericana se enfrentan a un elevado grado de competición. Además, se constata, desde la perspectiva de estudio multivariable, que, por lo menos descriptivamente, una variable clasificadora categórica como el sexo, resulta muy poco significativa formar grupos diferenciados entre los estudiantes con aspiraciones de ingreso, asunto que contrasta con los relatos socio-populistas basados en falacias _ad hominem_. El dato, si es fino, siempre será objetivo.

Complementariamente, todas las pruebas de normalidad multivariante resultaron negativas, salvo que a nivel univariado la variable **CGPA** presentó distribución normal en todas ellas. Así, el deterioro de las propiedades de independencia lineal juegan a favor de la síntesis de información a través de la estimación de componentes principales. Este asunto será tratado en el siguiente trabajo de este mismo curso.

Por último, es importante resaltar el aspecto técnico relacionado con el procesamiento estadístico hecho en este estudio a nivel de robustez, eficiencia e integración que R, RStudio y RMarkdown ofrecen al usuario para que este se pueda enfocar en él sin pasar mayores inconvenientes con el soporte documental para presentarlo.

## **Referencias**